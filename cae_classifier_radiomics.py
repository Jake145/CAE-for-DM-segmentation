# -*- coding: utf-8 -*-
"""CAE_Classifier_RADIOMICS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SP-9o3zcFEGXKvFXMMUyHVY8VYjWCWOP

#In questo notebook si allena la rete definita in CAE_Classifier_No_RADIOMICS.ipynb, ma con la caratteristica di estrarre le feature dalle immagini con Pyradiomics, con si fa una PCA per trovare le componenti di maggiore risalto da dare alla rete per migliorare la classificazione delle immagini.

# Carichiamo i dati dal Drive
"""

from google.colab import drive #remember to add the features from the data if you can load it correctly
drive.mount('/content/drive')

imagepath='/content/drive/My Drive/large_sample_Im_segmented_ref/0003s1_1_1_1_resized.pgm'
masspath='/content/drive/My Drive/large_sample_Im_segmented_ref/0003s1_1_1_1_mass_mask.pgm'

"""#Import che servono"""

import glob
import os
import numpy as np
from keras.utils import to_categorical
import matplotlib.pyplot as plt
from skimage import io, transform

"""# Possiamo vedere un esempio dei dati a disposizione"""

img = io.imread(masspath)
img2 = io.imread(imagepath)
plt.figure(figsize=(14,4))
plt.subplot(1,2,2)
plt.title('image')
plt.imshow(img2)
plt.subplot(1,2,1)
plt.title('real mass')
plt.imshow(img)
plt.show()

"""Per poter utilizzare Pyradiomics, è necessario utilizzare un format di immagini compatibile, dunque si convertono le immagini in .png e si normalizza subito le maschere, in quanto pyradiomics legge i path e cerca maschere normalizzate."""

pngpath='/content/drive/My Drive/GoodPNGMassesV2'

"""Questa funzione deve essere convertita in multiprocessing."""

import cv2
x_id ="_resized"
y_id="_mass_mask"
for f in glob.glob(dataset_path+'/*'):
  try: 
    image=plt.imread(f)
    if x_id in f:
      image=image
    elif y_id in f:
      image=image/255
    else:
      print('error, no mask or mass files')
    f=f.replace('.pgm','.png')
    f=f.replace('/content/drive/My Drive/large_sample_Im_segmented_ref/','')

    status = cv2.imwrite(os.path.join(endpath,f),image)
  except:
    pass

"""Importiamo la funzione read_dataset e normalizziamo le immagini"""

X_rad,Y_rad,LABELS_rad = read_dataset(endpath,'png')
X_rad = X_rad/255
Y_rad.min(),Y_rad.max()

"""#In questa sezione estraiamo le feature con pyradiomics e facciamo la PCA

"""

!pip install pyradiomics

"""Ora si estraggono le feature e si mettono in un dizionario che verrà poi convertito in un pandas dataframe"""

import radiomics
from radiomics import featureextractor 
x_id ="_resized"
y_id="_mass_mask"
ext='png'
fnames = glob.glob(os.path.join(endpath, f"*{x_id}.{ext}"))
fnamesmask = glob.glob(os.path.join(endpath, f"*{y_id}.{ext}"))

extractor = featureextractor.RadiomicsFeatureExtractor()

#Nel caso vi sia una categoria di feature che non interessano, si possono
#selezionare dopo aver disabilitato tutte le altre e abilitato quelle che interessano

#extractor.disableAllFeatures()
#extractor.enableFeatureClassByName('firstorder')
#extractor.enableFeatureClassByName('glcm')
#extractor.enableFeatureClassByName('gldm')
#extractor.enableFeatureClassByName('glrlm')
#extractor.enableFeatureClassByName('glszm')
#extractor.enableFeatureClassByName('ngtdm')
#extractor.enableFeatureClassByName('shape')

dataframe={f.replace(endpath,''):extractor.execute(f, f.replace(x_id,y_id)) for f in fnames}

import pandas as pd

Pandata=pd.DataFrame(dataframe)

Pandata

"""Qui vediamo tutti i campi. Naturalmente quelli che riguardano la versione dei pacchetti non interessano, quindi li eliminiamo"""

Pandata.index

"""Con questo ciclo si trovano i campi che non interessano"""

for i,name in enumerate(Pandata.index):
  if 'diagnostics' in Pandata.index[i]:
    print(i)  
  else:
    pass

"""Eliminiamo quei campi e facciamo la trasposta"""

Pandataframe=Pandata.drop(Pandata.index[0:22]).T

Pandataframe

"""Ora che abbiamo le feature, facciamo una pca per trovare le componenti che descrivono al meglio la variazione dei dati"""

X_train_rad, X_test_rad, Y_train_rad, Y_test_rad,class_train_rad,class_test_rad,feature_train,feature_test = train_test_split(X_rad, Y_rad,LABELS_rad,Pandataframe, test_size=0.2, random_state=42)

"""Per prima cosa si fa la rinormalizzazione dei dati"""

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
feature_train = sc.fit_transform(feature_train)
feature_test = sc.transform(feature_test)

from sklearn.decomposition import PCA

pca = PCA()
feature_train = pca.fit_transform(feature_train)
feature_test = pca.transform(feature_test)
explained_variance = pca.explained_variance_ratio_

explained_variance

"""Abbiamo trovato 93 feature, ma come si vede solo le prime sono significative. Guardiamo quali sono quelle che descrivono maggiormente la variazione"""

percentage_var_explained = pca.explained_variance_ratio_;  
cum_var_explained=np.cumsum(percentage_var_explained)
#plot spettro della PCA    
plt.figure(figsize=(6,4))
plt.clf()  
plt.plot(cum_var_explained,linewidth=2)  
plt.axis('tight')  
plt.grid() 
plt.xlabel('n_components') 
plt.ylabel('Cumulative_Variance_explained')  
plt.show()

"""Stampiamo quanta variazione si descrive al variare del numero di componenti"""

exp_var_cumsum=pd.Series(np.round(pca.explained_variance_ratio_.cumsum(),4)*100)  
for index,var in enumerate(exp_var_cumsum):  
    print('if n_components= %d,   variance=%f' %(index,np.round(var,3)))

"""Manteniamo le prime tre"""

from sklearn.decomposition import PCA

pca = PCA(n_components=3) 
feature_train = pca.fit_transform(feature_train)
feature_test = pca.transform(feature_test)

"""#Ora si prosegue importando i modelli con in input anche le features e si definisce una nuova classe di generatore che permette di avere anche le feature"""

from keras.preprocessing.image import ImageDataGenerator
from sklearn.utils import shuffle

train_datagen = ImageDataGenerator(
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        vertical_flip= True,
        fill_mode='reflect')

transform = train_datagen.get_random_transform((124,124)) 
transform

import keras
class MassesSequence_radiomics(keras.utils.Sequence):
    """ Classe per il data augmentation per CAE con feature radiomiche """

    def __init__(self, x, y,label_array,features, img_gen, batch_size=10, shape=(124,124)):
        """ Inizializza la sequenza

        Parametri::

        x (np.array): immagini
        y (np.array): maschere
        label_array (np.array): label di classificazione
        features (np.array): feature ottenute con pyradiomics
        batch_size (int): dimensioni della batch
        img_gen (ImageDatagenerator): istanza di ImageDatagenerator
        shape (tuple): shape dell'immagine. Di Default (124, 124)

        """
        self.x, self.y,self.label_array,self.features = x, y,label_array,features
        self.shape = shape
        self.img_gen = img_gen
        self.batch_size = batch_size


    def __len__(self):
        return len(self.x) // self.batch_size

    def on_epoch_end(self):
        """Shuffle the dataset at the end of each epoch."""
        self.x, self.y ,self.label_array,self.features= shuffle(self.x, self.y,
                                                                self.label_array,self.features)

    def process(self, img, transform):
        """ Apply a transformation to an image """
        img = self.img_gen.apply_transform(img, transform)
        return img
            
    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_label_array = self.label_array[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_features = self.features[idx * self.batch_size:(idx + 1) * self.batch_size]


        X=[];
        Y=[];
        Classes=[];
        Features=[]
        
        for image, mask,label,feature in zip(self.x, self.y,self.label_array,self.features):
            transform = self.img_gen.get_random_transform(self.shape)
            X.append(self.process(image, transform))
            Y.append(self.process(mask, transform)>0.2)
            Classes.append(label)
            Features.append(feature)

          
        return [np.asarray(X,np.float64),np.asarray(Features,np.float64)], [np.asarray(Y,np.float64) ,np.asarray(Classes,np.float)]

X_train_rad_tr, X_train_rad_val, Y_train_rad_tr, Y_train_rad_val,class_train_rad_tr,class_train_rad_val,feature_train_tr,feature_train_val = train_test_split(X_train_rad, Y_train_rad, to_categorical(class_train,2),feature_train, test_size=0.2, random_state=24)

mass_gen_rad = MassesSequence_radiomics(X_train_rad_tr, Y_train_rad_tr,class_train_rad_tr,feature_train_tr, train_datagen)

batch=mass_gen_rad[6]

batch[0].shape

"""Ora importiamo i modelli e facciamo il training. Questa parte del notebook contiene parti di codice simile alla versione senza pyradiomics, dunque non vi sono riportati i commenti di quella versione"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

"""importiamo i modelli con input sia l'immagine che le feature"""

import tensorflow as tf
import datetime, os

model_rad = make_model_rad_REGULIZER() 
model_rad.summary()

logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)

checkpoint_filepath = 'weights.{epoch:02d}-{val_loss:.2f}.h5'
model_checkpoint_callback = keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_filepath,
    monitor='val_classification_output_auc',
    mode='max',
    save_best_only=True)

model_rad.compile(optimizer='adam', loss={'decoder_output':'binary_crossentropy','classification_output':'categorical_crossentropy'},
                  metrics={'decoder_output':'MAE','classification_output':tf.keras.metrics.AUC()})

epoch_number= 50

history_rad = model_rad.fit(mass_gen_rad, steps_per_epoch=len(mass_gen_rad), epochs=epoch_number, 
                        validation_data=([X_train_rad_val,feature_train_val] ,[Y_train_rad_val,class_train_rad_val]),
                        callbacks=[tensorboard_callback])

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs

modelviewer(history_rad)

"""Carichiamo il modello con le prestazioni migliori"""

model_rad = keras.models.load_model('/content/drive/MyDrive/weights.35-0.47.h5')

"""Visualizziamo alcune immagini ottenute con la rete"""

idx=67
xtrain = X_train_rad[idx][np.newaxis,...]
ytrain = Y_train_rad[idx][np.newaxis,...]
xtrain.shape

plt.figure(figsize=(14,4))
plt.subplot(1,3,1)
plt.imshow(xtrain.squeeze())
plt.subplot(1,3,2)
plt.imshow(ytrain.squeeze())
plt.subplot(1,3,3)
plt.imshow(otsu(model_rad.predict([xtrain,feature_train[idx][np.newaxis,...]])[0].squeeze()))

"""Ora su immagini di test"""

idx=16
xtest = X_test[idx][np.newaxis,...]
ytest = Y_test[idx][np.newaxis,...]
xtest.shape

plt.figure(figsize=(14,4))
plt.subplot(1,3,1)
plt.imshow(xtest.squeeze())
plt.subplot(1,3,2)
plt.imshow(ytest.squeeze())
plt.subplot(1,3,3)
plt.imshow(otsu(model_rad.predict([xtest,feature_test[idx][np.newaxis,...]])[0].squeeze()))

"""Valutiamo i coefficienti di dice medi

The average Dice on the train set is:
"""

dice_vectorized(Y_train,otsu(model_rad.predict([X_train,feature_train])[0])).mean()

dice_vectorized(Y_test,otsu(model_rad.predict([X_test,feature_test])[0])).mean()

"""Visualizziamo una heatmap di attivazione del layer convoluzionale prima del fully connected del classificatore"""

heatmap_rad(X_test[18],feature_test[18],model_rad)

"""Vediamo ora la curva roc e l'AUC"""

from sklearn.metrics import roc_curve
y_pred = model_rad.predict([X_test_rad,feature_test])[1]
fpr, tpr, thresholds = roc_curve(class_test, [item[0] for _,item in enumerate(y_pred)],pos_label=0)

from sklearn.metrics import auc
auc = auc(fpr, tpr)

plot_roc_curve(fpr, tpr)
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TUNER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPLFScQvQJWL",
        "outputId": "08f13619-40ce-4194-d39a-893d2ce2b21f"
      },
      "source": [
        "from google.colab import drive #remember to add the features from the data if you can load it correctly\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9adQPDUxydBv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d74a0e9-bf8d-48d4-efac-a11579db6b71"
      },
      "source": [
        "!pip install SimpleITK\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting SimpleITK\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/85/6a7ce61f07cdaca722dd64f028b5678fb0a9e1bf66f534c2f8dd2eb78490/SimpleITK-2.0.2-cp36-cp36m-manylinux2010_x86_64.whl (47.4MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4MB 60kB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnetAfhMynxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7dca09f-8f25-4922-a518-07cb1c37e6d0"
      },
      "source": [
        "!pip install pyradiomics"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyradiomics\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/ad/bbf185d864945c96b67390abc01b3450692816d53e9489de3a87c321f947/pyradiomics-3.0.1-cp36-cp36m-manylinux1_x86_64.whl (157kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 2.8MB/s \n",
            "\u001b[?25hCollecting pykwalify>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/fd/ac2161cce19fd67a18c269073f8e86292b5511acec6f8ef6eab88615d032/pykwalify-1.8.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from pyradiomics) (1.19.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pyradiomics) (1.15.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from pyradiomics) (1.1.1)\n",
            "Requirement already satisfied: SimpleITK>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from pyradiomics) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from pykwalify>=1.6.0->pyradiomics) (2.8.1)\n",
            "Collecting ruamel.yaml>=0.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/39/186f14f3836ac5d2a6a042c8de69988770e8b9abb537610edc429e4914aa/ruamel.yaml-0.16.12-py2.py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from pykwalify>=1.6.0->pyradiomics) (0.6.2)\n",
            "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/ff/ec25dc01ef04232a9e68ff18492e37dfa01f1f58172e702ad4f38536d41b/ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 6.6MB/s \n",
            "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, ruamel.yaml, pykwalify, pyradiomics\n",
            "Successfully installed pykwalify-1.8.0 pyradiomics-3.0.1 ruamel.yaml-0.16.12 ruamel.yaml.clib-0.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-8QdxFfQybx",
        "outputId": "b7f1cdf6-bf54-4d87-bf6e-212649edd3f7"
      },
      "source": [
        "!pip install keras-tuner"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\r\u001b[K     |█████▏                          | 10kB 18.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 5.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (20.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.7)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2020.12.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (1.0.0)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp36-none-any.whl size=78939 sha256=990ef60ec2df3730323e57b08472451fecaace24adb3f828367e49a31781b076\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15358 sha256=846927738592db34835238e82fc04207b0de8080a2fe68f45702e76886a1d621\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCJU88PIQs4F"
      },
      "source": [
        "import os\r\n",
        "from PIL import Image\r\n",
        "from skimage.io import imread\r\n",
        "import datetime\r\n",
        "import keras\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from sklearn.utils import shuffle\r\n",
        "from keras.constraints import unit_norm,min_max_norm,max_norm\r\n",
        "from tensorflow.keras import regularizers\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "import pandas as pd\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from sklearn.utils import shuffle\r\n",
        "import glob\r\n",
        "import radiomics\r\n",
        "from radiomics import featureextractor\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from keras.utils import to_categorical\r\n",
        "import tensorflow as tf\r\n",
        "#import sys\r\n",
        "#sys.path\r\n",
        "#sys.path.append('C:/Users/pensa/Desktop/CAE-for-DM-segmentation/functioncae')\r\n",
        "import time\r\n",
        "LOG_DIR = f\"{int(time.time())}\"\r\n",
        "import kerastuner\r\n",
        "from kerastuner.tuners import RandomSearch, BayesianOptimization\r\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\r\n",
        "import time\r\n",
        "LOG_DIR = f\"{int(time.time())}\"\r\n",
        "\r\n",
        "import logging"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezy52lW0P0Wt"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LChDnmIsQUcB"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip= True,\n",
        "        fill_mode='reflect')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pm5ViJpQUcE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7e13964-ca57-43fe-87d7-54981994e0c4"
      },
      "source": [
        "transform = train_datagen.get_random_transform((124,124)) \n",
        "transform\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'brightness': None,\n",
              " 'channel_shift_intensity': None,\n",
              " 'flip_horizontal': 0,\n",
              " 'flip_vertical': 0,\n",
              " 'shear': -0.0075775704271277,\n",
              " 'theta': 30.985704274020577,\n",
              " 'tx': -11.426083718455464,\n",
              " 'ty': -19.684214322472936,\n",
              " 'zx': 0.9843877442936487,\n",
              " 'zy': 1.0913747563965328}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnv6rjgMlscN"
      },
      "source": [
        "import keras\r\n",
        "class MassesSequence_radiomics(keras.utils.Sequence):\r\n",
        "    \"\"\" Classe per il data augmentation per CAE con feature radiomiche \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, x, y,label_array,features, img_gen, batch_size=10, shape=(124,124)):\r\n",
        "        \"\"\" Inizializza la sequenza\r\n",
        "\r\n",
        "        Parametri::\r\n",
        "\r\n",
        "        x (np.array): immagini\r\n",
        "        y (np.array): maschere\r\n",
        "        label_array (np.array): label di classificazione\r\n",
        "        features (np.array): feature ottenute con pyradiomics\r\n",
        "        batch_size (int): dimensioni della batch\r\n",
        "        img_gen (ImageDatagenerator): istanza di ImageDatagenerator\r\n",
        "        shape (tuple): shape dell'immagine. Di Default (124, 124)\r\n",
        "\r\n",
        "        \"\"\"\r\n",
        "        self.x, self.y,self.label_array,self.features = x, y,label_array,features\r\n",
        "        self.shape = shape\r\n",
        "        self.img_gen = img_gen\r\n",
        "        self.batch_size = batch_size\r\n",
        "\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.x) // self.batch_size\r\n",
        "\r\n",
        "    def on_epoch_end(self):\r\n",
        "        \"\"\"Shuffle the dataset at the end of each epoch.\"\"\"\r\n",
        "        self.x, self.y ,self.label_array,self.features= shuffle(self.x, self.y,\r\n",
        "                                                                self.label_array,self.features)\r\n",
        "\r\n",
        "    def process(self, img, transform):\r\n",
        "        \"\"\" Apply a transformation to an image \"\"\"\r\n",
        "        img = self.img_gen.apply_transform(img, transform)\r\n",
        "        return img\r\n",
        "            \r\n",
        "    def __getitem__(self, idx):\r\n",
        "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\r\n",
        "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\r\n",
        "        batch_label_array = self.label_array[idx * self.batch_size:(idx + 1) * self.batch_size]\r\n",
        "        batch_features = self.features[idx * self.batch_size:(idx + 1) * self.batch_size]\r\n",
        "\r\n",
        "\r\n",
        "        X=[];\r\n",
        "        Y=[];\r\n",
        "        Classes=[];\r\n",
        "        Features=[]\r\n",
        "        \r\n",
        "        for image, mask,label,feature in zip(self.x, self.y,self.label_array,self.features):\r\n",
        "            transform = self.img_gen.get_random_transform(self.shape)\r\n",
        "            X.append(self.process(image, transform))\r\n",
        "            Y.append(self.process(mask, transform)>0.2)\r\n",
        "            Classes.append(label)\r\n",
        "            Features.append(feature)\r\n",
        "\r\n",
        "          \r\n",
        "        return [np.asarray(X,np.float64),np.asarray(Features,np.float64)], [np.asarray(Y,np.float64) ,np.asarray(Classes,np.float)]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnRY2sexP8l8"
      },
      "source": [
        "import PIL\r\n",
        "from PIL import Image\r\n",
        "import cv2\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import glob\r\n",
        "from skimage.io import imread\r\n",
        "import time\r\n",
        "import re\r\n",
        "import warnings\r\n",
        "import logging\r\n",
        "\r\n",
        "logger = logging.getLogger(__name__)\r\n",
        "logger.setLevel(logging.INFO)\r\n",
        "\r\n",
        "formatter = logging.Formatter('%(levelname)s:%(name)s:%(message)s')\r\n",
        "\r\n",
        "file_handler = logging.FileHandler('CAE_functions.log')\r\n",
        "file_handler.setFormatter(formatter)\r\n",
        "\r\n",
        "logger.addHandler(file_handler)\r\n",
        "\r\n",
        "\r\n",
        "def save_newext(file_name,data_path,ext1,ext2,endpath):\r\n",
        "  \"\"\"Riscrive le immagini in formato leggibile per pyradiomics\r\n",
        "  :type file_name: str\r\n",
        "  :param file_path: nome del file della immagine\r\n",
        "\r\n",
        "  :type data_path: str\r\n",
        "  :param data_path: percorso della cartella dove si trova la immagine\r\n",
        "\r\n",
        "  :type ext1: str\r\n",
        "  :param ext1: stringa identificativa dell'estenzione di partenza della immagine\r\n",
        "\r\n",
        "  :type ext2: str\r\n",
        "  :param ext2: stringa identificativa dell'estenzione finale della immagine\r\n",
        "\r\n",
        "  :type endpath: str\r\n",
        "  :param endpath: percorso della cartella di arrivo\r\n",
        "  :returns: dopo aver salvato il nuovo file, restituisce l'esito\r\n",
        "  :rtype: bool\r\n",
        "\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  if ext1==ext2:\r\n",
        "    logger.debug(f'il file {file_name} in {data_path} ha già la estenzione {ext2}' )\r\n",
        "  try:\r\n",
        "    image=plt.imread(os.path.join(data_path,file_name))\r\n",
        "    file_name=file_name.replace(f'.{ext1}',f'.{ext2}') #insert logging warning if ext1==ext2\r\n",
        "    logger.info(f'read {os.path.join(data_path,file_name)} and changed extension from {ext1} to {ext2}')\r\n",
        "  except:\r\n",
        "    raise Exception('immagine o path non trovati')\r\n",
        "    logger.exception(f'Non ho trovato {file_name} in {data_path}')\r\n",
        "  status = cv2.imwrite(os.path.join(endpath,file_name),image)\r\n",
        "  logger.info(f'ho scritto il file {file_name} in {endpath} come .{ext2} ')\r\n",
        "  return status\r\n",
        "\r\n",
        "def unit_masks(file_name,data_path,ext1,ext2, endpath):\r\n",
        "  \"\"\"Normalizza i valori dei pixel delle maschere già nei file per essere utilizzati con pyradiomics. Permette inoltre di cambiare l'estenzione da .pgm a .png o qualunque altra estenzione supportata.\r\n",
        "\r\n",
        "  :type file_name: str\r\n",
        "  :param file_path: nome del file della maschera\r\n",
        "\r\n",
        "  :type data_path: str\r\n",
        "  :param data_path: percorso della cartella dove si trova la maschera\r\n",
        "\r\n",
        "  :type ext1: str\r\n",
        "  :param ext1: stringa identificativa dell'estenzione di partenza della maschera\r\n",
        "\r\n",
        "  :type ext2: str\r\n",
        "  :param ext2: stringa identificativa dell'estenzione finale della maschera\r\n",
        "\r\n",
        "  :type endpath: str\r\n",
        "  :param endpath: percorso della cartella di arrivo\r\n",
        "\r\n",
        "  :returns: dopo aver salvato il nuovo file, restituisce l'esito e l'immagine\r\n",
        "  :rtype: bool, array\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  try:\r\n",
        "    image=plt.imread(os.path.join(data_path,file_name))\r\n",
        "    logger.info(f'Ho letto {file_name} in {data_path}')\r\n",
        "  except:\r\n",
        "    raise Exception('immagine o path non trovati!')\r\n",
        "    logger.exception(f'{file_name} non trovato in {data_path}')\r\n",
        "  image=image/255\r\n",
        "  file_name=file_name.replace(f'.{ext1}',f'.{ext2}')\r\n",
        "  status = cv2.imwrite(os.path.join(endpath,file_name),image)\r\n",
        "  logging.info(f'ho scritto {file_name} in {endpath} con successo')\r\n",
        "  return status,image\r\n",
        "\r\n",
        "def read_dataset(dataset_path,ext,benign_label,malign_label,x_id =\"_resized\", y_id=\"_mass_mask\"):\r\n",
        "  \"\"\"Data la cartella con le maschere e le immagini, restituisce i vettori con le immagini, le maschere e le classi. Restituisce i vettori come tensori da dare alla rete.\r\n",
        "\r\n",
        "  :type dataset_path: str\r\n",
        "  :param dataset_path: Cartella con le immagini e le relative maschere\r\n",
        "\r\n",
        "  :type data_path: str\r\n",
        "  :param data_path: percorso della cartella dove si trova la maschera\r\n",
        "\r\n",
        "  :type ext: str\r\n",
        "  :param ext: stringa identificativa dell'estenzione delle immagini e maschere\r\n",
        "\r\n",
        "  :type x_id: str\r\n",
        "  :param x_id: identificativo delle immagini\r\n",
        "\r\n",
        "  :type x_id: str\r\n",
        "  :param x_id: identificativo delle maschere\r\n",
        "\r\n",
        "  :type benign_label: str\r\n",
        "  :param benign_label: identificativo delle masse benigne\r\n",
        "\r\n",
        "  :type malign_label: str\r\n",
        "  :param malign_label: identificativo delle masse maligne\r\n",
        "\r\n",
        "  :returns: restituisce i vettori con le immagini, le maschere e le classi\r\n",
        "  :rtype: array\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  fnames = glob.glob(os.path.join(dataset_path, f\"*{x_id}.{ext}\"))\r\n",
        "  logger.info(f'ho analizzato {dataset_path} cercando le immagini')\r\n",
        "  if fnames == []:\r\n",
        "    raise Exception('Niente immagini! Il path è sbagliato, magari x_id o ext sono sbagliati! ')\r\n",
        "    logger.exception('Non ho trovato immagini in {dataset_path}')\r\n",
        "  else:\r\n",
        "    pass\r\n",
        "  X = []\r\n",
        "  Y = []\r\n",
        "  class_labels=[]\r\n",
        "  for fname in fnames:\r\n",
        "      X.append(plt.imread(fname)[1:,1:,np.newaxis])\r\n",
        "      Y.append(plt.imread(fname.replace(x_id, y_id))[1:,1:,np.newaxis])\r\n",
        "      if benign_label in fname:\r\n",
        "        class_labels.append(0)\r\n",
        "      elif malign_label in fname:\r\n",
        "        class_labels.append(1)\r\n",
        "  logger.info(f'ho preso le immagini e le maschere da {dataset_path}, ho trovato tutto e ho creato gli array delle immagini, maschere e classi')\r\n",
        "  return np.array(X), np.array(Y) , np.array(class_labels)\r\n",
        "\r\n",
        "def read_dataset_big(dataset_path_mass,dataset_path_mask,benign_label,malign_label,ext='png'):\r\n",
        "  \"\"\"Versione di read_dataset per il dataset del TCIA. Data la cartella con le maschere e le immagini, restituisce i vettori con i filepath delle immagini, le maschere e le classi.\r\n",
        "\r\n",
        "  :type dataset_path_mass: str\r\n",
        "  :param dataset_path_mass: Cartella con le immagini\r\n",
        "\r\n",
        "  :type dataset_path_mask: str\r\n",
        "  :param dataset_path_mask: percorso della cartella dove si trovano le maschera\r\n",
        "\r\n",
        "  :type ext: str\r\n",
        "  :param ext: stringa identificativa dell'estenzione delle immagini e maschere\r\n",
        "\r\n",
        "\r\n",
        "  :returns: restituisce i vettori con i path delle immagini, le maschere e le classi\r\n",
        "  :rtype: array\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  fnames  = glob.glob(os.path.join(dataset_path_mass, f\"*.{ext}\"))\r\n",
        "  logger.info(f'ho analizzato {dataset_path_mass} cercando le immagini')\r\n",
        "\r\n",
        "  if fnames == []:\r\n",
        "    raise Exception('Niente immagini! Il path è sbagliato, magari ext è sbagliato! ')\r\n",
        "    logger.exception('Non ho trovato immagini in {dataset_path_mass}')\r\n",
        "\r\n",
        "  else:\r\n",
        "    pass\r\n",
        "  masknames = glob.glob(os.path.join(dataset_path_mask, f\"*.{ext}\"))\r\n",
        "  logger.info(f'ho analizzato {dataset_path_mask} cercando le maschere')\r\n",
        "\r\n",
        "  if masknames==[]:\r\n",
        "    raise Exception('Immagini o path non trovati!')\r\n",
        "    logger.exception('Non ho trovato maschere in {dataset_path_mask}')\r\n",
        "\r\n",
        "  else:\r\n",
        "    pass\r\n",
        "  X = []\r\n",
        "  Y = []\r\n",
        "  class_labels=[]\r\n",
        "  for fname in fnames:\r\n",
        "    try:\r\n",
        "      assert(fname.replace(dataset_path_mass, dataset_path_mask) in masknames)\r\n",
        "      logger.debug(f'sto verificando che {fname} sia in {dataset_path_mask}')\r\n",
        "      Y.append(fname.replace(dataset_path_mass, dataset_path_mask))\r\n",
        "      X.append(fname)\r\n",
        "\r\n",
        "      if benign_label in fname:\r\n",
        "        class_labels.append(0)\r\n",
        "      elif malign_label in fname:\r\n",
        "        class_labels.append(1)\r\n",
        "    except:\r\n",
        "      warnings.warn(f\"Attenzione, per {fname} non vi è corrispondenza in {dataset_path_mask}, controlla che l'immagine non sia corrotta o non sia mancante\")\r\n",
        "      logger.warning(f\"Attenzione, per {fname} non vi è corrispondenza in {dataset_path_mask}, controlla che l'immagine non sia corrotta o non sia mancante\")\r\n",
        "      pass\r\n",
        "\r\n",
        "  return np.array(X), np.array(Y) , np.array(class_labels)\r\n",
        "\r\n",
        "import pickle\r\n",
        "import SimpleITK as sitk\r\n",
        "import radiomics\r\n",
        "from radiomics import featureextractor\r\n",
        "\r\n",
        "def radiomic_dooer(list_test,datapath,endpath,lab,extrc):\r\n",
        "\r\n",
        "  \"\"\"Funzione per estrarre le feature con pyradiomics e salvarle in un dizionario.\r\n",
        "\r\n",
        "  :type list_test: list\r\n",
        "  :param list_test: lista con path immagine e relativa maschera normalizzata\r\n",
        "  :type datapath: str\r\n",
        "  :param datapath: percorso cartella dove si trova l'immagine\r\n",
        "  :type endpath: str\r\n",
        "  :param endpath: cartella dove si salva il pickle del dizionario\r\n",
        "  :type lab: int\r\n",
        "  :param lab: label per indicare la maschera, va da 1 a 255\r\n",
        "  :extrc type: str\r\n",
        "  :extr param: classe estrattore di pyradiomics\r\n",
        "\r\n",
        "  :returns: dopo aver salvato il pickle, restituisce il tempo impiegato\r\n",
        "  :rtype: str\r\n",
        "\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  b=time.perf_counter()\r\n",
        "  try:\r\n",
        "    logger.debug(f'sto cercando di estrarre le feature da {list[0]} utilizzando come maschera {list[1]}')\r\n",
        "    info=extrc.execute(list_test[0],list_test[1],lab)\r\n",
        "\r\n",
        "  except:\r\n",
        "    raise Exception('Problema con pyradiomics: forse vi è un problema col label o i path. Controlla che pyradiomics sia installato e che da radiomics sia importato featureextractor')\r\n",
        "    logger.exception(f'Problema con pyradiomics: forse vi è un problema col label o i path per {list[0]} e {list[1]} . Controlla che pyradiomics sia installato e che da radiomics sia importato featureextractor')\r\n",
        "  c=time.perf_counter()\r\n",
        "  logging.info(f'time to extract:{c-b}')\r\n",
        "  d=time.perf_counter()\r\n",
        "  pattern=re.compile('[M][\\w-]*[0-9]*[\\w]{13}')\r\n",
        "  logging.debug(f'in regex il pattern è {pattern}')\r\n",
        "  name=re.findall(pattern,list_test[0])\r\n",
        "  logging.debug(f'il patter che sto cercando è {name}')\r\n",
        "\r\n",
        "  dict_r={name[0]:info}\r\n",
        "  try:\r\n",
        "    with open(os.path.join(endpath,f'feats_{name[0]}.pickle'), 'wb') as handle:\r\n",
        "      pickle.dump(dict_r, handle, protocol=pickle.HIGHEST_PROTOCOL)\r\n",
        "      logging.info(f'salvato il pickle feats_{name[0]}.pickle in {endpath}')\r\n",
        "  except:\r\n",
        "    raise Exception('Qualcosa è andato male nel definire il path di arrivo, controlla che endpath sia giusto')\r\n",
        "    logger.exception(f'Qualcosa è andato male nel definire il path di arrivo {datapath}, controlla che {endpath} sia un endpath giusto')\r\n",
        "  del(dict_r)\r\n",
        "  logger.info(f'time to update:{d-c}')\r\n",
        "\r\n",
        "  return 'time to update:{d-c}'\r\n",
        "\r\n",
        "def read_pgm_as_sitk(image_path):\r\n",
        "  \"\"\"Legge un .pgm come una immagine Simple ITK\r\n",
        "\r\n",
        "  :type image_path: str\r\n",
        "  :param image_path: path dell'immagine voluta\r\n",
        "  :returns: restituisce l'immagine da far leggere a pyradiomics\r\n",
        "  :rtype: array\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  np_array = np.asarray(PIL.Image.open(image_path))\r\n",
        "  logger.info(f'sto leggendo {image_path}')\r\n",
        "  sitk_image = sitk.GetImageFromArray(np_array)\r\n",
        "  logger.info(f'sto convertendo {image_path}')\r\n",
        "\r\n",
        "  return sitk_image\r\n",
        "\r\n",
        "def dict_update_radiomics(data_path,dictionary):\r\n",
        "\r\n",
        "  \"\"\"Funzione per unire i vari dizionari creati con radiomic_dooer per poi creare il dataframe\r\n",
        "\r\n",
        "  :type data_path: str\r\n",
        "  :param data_path: percorso del pickle da aprire\r\n",
        "  :type dictionary: dict\r\n",
        "  :param dictionary: dizionario generale del dataframe\r\n",
        "  :returns: restituisce il dizionario aggiornato\r\n",
        "  :rtype: dict\r\n",
        "\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  with open(data_path, 'rb') as handle:\r\n",
        "    logger.info(f'ho aperto {data_path}')\r\n",
        "    b = pickle.load(handle)\r\n",
        "    logger.info(f'ho caricato {handle}')\r\n",
        "    dictionary.update(b)\r\n",
        "    logger.info(f'ho fatto un update a {dictionary}')\r\n",
        "\r\n",
        "\r\n",
        "  return(dictionary)\r\n",
        "\r\n",
        "def blender(img1,img2,a,b):\r\n",
        "  \"\"\"Funzione per sovraimporre due immagini con sfumatura\r\n",
        "\r\n",
        "  :type img1: array numpy\r\n",
        "  :param img1: immagine da sovrapporre\r\n",
        "  :type img2: array numpy\r\n",
        "  :param img2: immagine da svrapporre\r\n",
        "  :type a: int or float\r\n",
        "  :param a: valore di sfumatura di img1\r\n",
        "  :type b: int or float\r\n",
        "  :param b: valore di sfumatura di img2\r\n",
        "  :returns: restituisce l'immagine sovrapposta\r\n",
        "  :rtype: array\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  try:\r\n",
        "    image=cv2.addWeighted(img1,a, img2, b,0)\r\n",
        "    logger.debug('sto cercando di sovrapporre le immagini con pesi rispettivamente {a} e {b}')\r\n",
        "  except:\r\n",
        "    raise Exception('Sovrapposizione non riuscita. Controllare che le immagini siano giuste e che a e b siano numeri.')\r\n",
        "    logger.exception('Sovrapposizione non riuscita. Controllare che le immagini siano giuste e che a e b siano numeri.')\r\n",
        "  logger.info('sovrapposizione riuscita')\r\n",
        "  return  image\r\n",
        "\r\n",
        "def dice(pred, true, k = 1):\r\n",
        "  \"\"\"Funzione per calcolare l'indice di Dice\r\n",
        "\r\n",
        "  :type pred: array numpy\r\n",
        "  :param pred: immagini predette dal modello\r\n",
        "  :type true: array numpy\r\n",
        "  :param true: immagini target\r\n",
        "  :type k: int\r\n",
        "  :param k: valore pixel true della maschera\r\n",
        "  :returns: restituisce il valore di Dice\r\n",
        "  :rtype: float\r\n",
        "\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  intersection = np.sum(pred[true==k]) * 2.0\r\n",
        "  try:\r\n",
        "    dice = intersection / (np.sum(pred) + np.sum(true))\r\n",
        "  except ZeroDivisionError:\r\n",
        "    logger.exception('provato a dividere per zero!')\r\n",
        "  logger.info(f'calcolato correttamente il dice ottenendo {dice}')\r\n",
        "  return dice\r\n",
        "\r\n",
        "def dice_vectorized(pred, true, k = 1):\r\n",
        "  \"\"\"\r\n",
        "  Versione vettorizzata per calcolare il coefficiente di dice\r\n",
        "\r\n",
        "  :type pred: array numpy\r\n",
        "  :param pred: immagini predette dal modello\r\n",
        "  :type true: array numpy\r\n",
        "  :param true: immagini target\r\n",
        "  :type k: int\r\n",
        "  :param k: valore pixel true della maschera\r\n",
        "  :returns: restituisce il dice medio\r\n",
        "  :rtype: float\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  intersection = 2.0 *np.sum(pred * (true==k), axis=(1,2,3))\r\n",
        "  try:\r\n",
        "    dice = intersection / (pred.sum(axis=(1,2,3)) + true.sum(axis=(1,2,3)))\r\n",
        "  except ZeroDivisionError:\r\n",
        "    logger.exception('provato a dividere per zero!')\r\n",
        "  logger.info(f'calcolato correttamente il dice medio ottenendo {dice}')\r\n",
        "  return dice\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "def modelviewer(model):\r\n",
        "  \"\"\"\r\n",
        "  Funzione per visualizzare l'andamento della loss di training e validazione per l'autoencoder e per il classificatore\r\n",
        "  :type model: str\r\n",
        "  :param model: history del modello di Keras ottenuto dalla funzione\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  plt.figure('modelviewer')\r\n",
        "  plt.subplot(2,1,1)\r\n",
        "  plt.title('autoencoder')\r\n",
        "  try:\r\n",
        "    plt.plot(model.history['decoder_output_loss'])\r\n",
        "    plt.plot(model.history['val_decoder_output_loss'])\r\n",
        "  except:\r\n",
        "    raise Exception('Attenzione, o model non è un modello Keras o il modello non ha i campi decoder_output_loss o val_decoder_output_loss')\r\n",
        "    logger.exception('Attenzione, o model non è un modello Keras o il modello non ha i campi decoder_output_loss o val_decoder_output_loss')\r\n",
        "  plt.legend(['loss', 'val_loss'])\r\n",
        "  plt.subplot(2,1,2)\r\n",
        "  plt.title('classifier')\r\n",
        "  try:\r\n",
        "    plt.plot(model.history['classification_output_loss'])\r\n",
        "    plt.plot(model.history['val_classification_output_loss'])\r\n",
        "  except:\r\n",
        "    raise Exception('Attenzione, il modello non ha i campi classification_output_loss o val_classification_output_loss')\r\n",
        "    logger.exception('Attenzione, il modello non ha i campi classification_output_loss o val_classification_output_loss')\r\n",
        "  plt.legend(['loss', 'val_loss'])\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "def heatmap(x,model):\r\n",
        "  \"\"\"\r\n",
        "  Funzione che mostra la heatmap dell'ultimo layer convoluzionale prima del classificatore senza funzionalità radiomiche\r\n",
        "\r\n",
        "  :type x: array numpy\r\n",
        "  :param x: immagine da segmentare\r\n",
        "\r\n",
        "  :type model: str\r\n",
        "  :param model: modello allenato\r\n",
        "  :returns: dopo aver plottato la heatmap sovrapposta e l'immagine a cui si riferisce, restituisce la heatmap\r\n",
        "  :rtype: array\r\n",
        "\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  img_tensor =x[np.newaxis,...]\r\n",
        "  preds = model.predict(img_tensor)[1]\r\n",
        "  argmax = np.argmax(preds)\r\n",
        "  conv_layer = model.get_layer(\"last_conv\")\r\n",
        "  heatmap_model = models.Model([model.inputs], [conv_layer.output, model.output])\r\n",
        "\r\n",
        "  with tf.GradientTape() as gtape:\r\n",
        "      conv_output, predictions = heatmap_model(img_tensor)\r\n",
        "      loss = predictions[1][:, np.argmax(predictions[1])]\r\n",
        "      grads = gtape.gradient(loss, conv_output)\r\n",
        "      pooled_grads = K.mean(grads, axis=(0, 1, 2))\r\n",
        "\r\n",
        "  heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)\r\n",
        "  heatmap = np.maximum(heatmap, 0)\r\n",
        "  max_heat = np.max(heatmap)\r\n",
        "  if max_heat == 0:\r\n",
        "      max_heat = 1e-10\r\n",
        "  heatmap /= max_heat\r\n",
        "\r\n",
        "\r\n",
        "  plt.matshow(heatmap.squeeze())\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  x = np.asarray(255*x, np.uint8)\r\n",
        "  heatmap = np.asarray(255*heatmap.squeeze(), np.uint8)\r\n",
        "\r\n",
        "\r\n",
        "  heatmap = cv2.resize(heatmap, (x.shape[1], x.shape[0]))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  plt.imshow(blender(x,heatmap,1,1))\r\n",
        "  plt.axis('off')\r\n",
        "  if argmax==1:\r\n",
        "    plt.title('the mass is malign')\r\n",
        "  else:\r\n",
        "    plt.title('the mass is benign')\r\n",
        "\r\n",
        "  return heatmap\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.python.keras import backend as K\r\n",
        "from tensorflow.keras import models\r\n",
        "\r\n",
        "def heatmap_rad(x,feature,model):\r\n",
        "  \"\"\"\r\n",
        "  Funzione che mostra la heatmap dell'ultimo layer convoluzionale prima del classificatore con funzionalità radiomiche\r\n",
        "\r\n",
        "  :type x: array numpy\r\n",
        "  :param x: immagine da segmentare\r\n",
        "  :type feature: array numpy\r\n",
        "  :param feature: feature estratte con pyradiomics\r\n",
        "  :type model: class\r\n",
        "  :param model: modello allenato\r\n",
        "  :returns: dopo aver plottato la heatmap sovrapposta e l'immagine a cui si riferisce, restituisce la heatmap\r\n",
        "  :rtype: array\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  img_tensor =x[np.newaxis,...]\r\n",
        "  feature_tensor=feature[np.newaxis,...]\r\n",
        "  preds = model.predict([img_tensor,feature_tensor])[1]\r\n",
        "  argmax = np.argmax(preds)\r\n",
        "  conv_layer = model.get_layer(\"last_conv\")\r\n",
        "  heatmap_model = models.Model([model.inputs], [conv_layer.output, model.output])\r\n",
        "\r\n",
        "  with tf.GradientTape() as gtape:\r\n",
        "      conv_output, predictions = heatmap_model([img_tensor,feature_tensor])\r\n",
        "      loss = predictions[1][:, np.argmax(predictions[1])]\r\n",
        "      grads = gtape.gradient(loss, conv_output)\r\n",
        "      pooled_grads = K.mean(grads, axis=(0, 1, 2))\r\n",
        "\r\n",
        "  heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)\r\n",
        "  heatmap = np.maximum(heatmap, 0)\r\n",
        "  max_heat = np.max(heatmap)\r\n",
        "  if max_heat == 0:\r\n",
        "      max_heat = 1e-10\r\n",
        "  heatmap /= max_heat\r\n",
        "\r\n",
        "  plt.figure('heatmap')\r\n",
        "  plt.matshow(heatmap.squeeze())\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "  x = np.asarray(255*x, np.uint8)\r\n",
        "  heatmap = np.asarray(255*heatmap.squeeze(), np.uint8)\r\n",
        "\r\n",
        "\r\n",
        "  heatmap = cv2.resize(heatmap, (x.shape[1], x.shape[0]))\r\n",
        "\r\n",
        "  plt.figure('Heatactivation')\r\n",
        "  plt.imshow(blender(x,heatmap,1,1))\r\n",
        "  plt.axis('off')\r\n",
        "  if argmax==1:\r\n",
        "    plt.title('the mass is malign')\r\n",
        "  else:\r\n",
        "    plt.title('the mass is benign')\r\n",
        "  plt.show()\r\n",
        "  return heatmap\r\n",
        "\r\n",
        "def plot_roc_curve(fper, tper,auc):\r\n",
        "  \"\"\"Funzione che fa il plot della curva roc\r\n",
        "\r\n",
        "  :type fper: float\r\n",
        "  :param fper: percentuale falsi positivi\r\n",
        "\r\n",
        "  :type tper: float\r\n",
        "  :param tper: percentuale veri positivi\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  plt.figure('AUC')\r\n",
        "  plt.plot(fper, tper, color='orange', label='ROC')\r\n",
        "  plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\r\n",
        "  plt.xlabel('False Positive Rate')\r\n",
        "  plt.ylabel('True Positive Rate')\r\n",
        "  plt.title('Receiver Operating Characteristic (ROC) Curve with AUC = %.2f'%auc)\r\n",
        "  plt.legend()\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "from skimage.filters import threshold_multiotsu\r\n",
        "\r\n",
        "def otsu(image,n_items=2):\r\n",
        "  \"\"\"Funzione che implementa l'algoritmo di Otsu per la segmentazione\r\n",
        "\r\n",
        "  :type image: numpy array\r\n",
        "  :param fper: immagine da segmentare\r\n",
        "  :type n_items: int\r\n",
        "  :param n_items: numero di oggetti da segmentare nell'immagine\r\n",
        "  :returns: restituisce l'immagine binarizzata\r\n",
        "  :rtype: array\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  thresholds = threshold_multiotsu(image,classes=n_items)\r\n",
        "  regions = np.digitize(image, bins=thresholds)\r\n",
        "  return regions"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Keki8WZTrq80"
      },
      "source": [
        "logger = logging.getLogger(__name__)\r\n",
        "logger.setLevel(logging.DEBUG)\r\n",
        "\r\n",
        "formatter = logging.Formatter('%(asctime)s:%(name)s:%(message)s')\r\n",
        "\r\n",
        "file_handler = logging.FileHandler('Tuner.log')\r\n",
        "file_handler.setLevel(logging.ERROR)\r\n",
        "file_handler.setFormatter(formatter)\r\n",
        "\r\n",
        "stream_handler = logging.StreamHandler()\r\n",
        "stream_handler.setFormatter(formatter)\r\n",
        "\r\n",
        "logger.addHandler(file_handler)\r\n",
        "logger.addHandler(stream_handler)\r\n",
        "\r\n",
        "from keras.layers import Conv2D, Conv2DTranspose, Input, Dropout,MaxPooling2D, UpSampling2D, Dense, Flatten\r\n",
        "from keras.models import Model, load_model\r\n",
        "from keras.layers.experimental.preprocessing import Resizing\r\n",
        "from keras.layers.merge import concatenate\r\n",
        "\r\n",
        "def build_model_rad_UNET(hp,shape=(124,124,1),feature_dim=(3,)):\r\n",
        "    input_tensor = Input(shape=shape)\r\n",
        "    input_vector= Input(shape=feature_dim)\r\n",
        "\r\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal',\r\n",
        "                            padding='same')(input_tensor)\r\n",
        "    c1 = Dropout(0.2)(c1)\r\n",
        "    c1 = Conv2D(16, (3, 3),activation='relu', kernel_initializer='he_normal',\r\n",
        "                            padding='same')(c1)\r\n",
        "    p1 =MaxPooling2D((2, 2))(c1)\r\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',\r\n",
        "                            padding='same')(p1)\r\n",
        "    c2 = Dropout(0.1)(c2)\r\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',\r\n",
        "                            padding='same')(c2)\r\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\r\n",
        "    p2 = Resizing(32,32,interpolation='nearest')(p2)\r\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',\r\n",
        "                            padding='same')(p2)\r\n",
        "\r\n",
        "\r\n",
        "    c3 = Dropout(0.2)(c3)\r\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',\r\n",
        "                            padding='same')(c3)\r\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\r\n",
        "    p3 = Resizing(16,16,interpolation='nearest')(p3)\r\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',\r\n",
        "                            padding='same')(p3)\r\n",
        "    c4 = Dropout(0.2)(c4)\r\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',\r\n",
        "                            padding='same')(c4)\r\n",
        "\r\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\r\n",
        "\r\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal',\r\n",
        "                            padding='same')(p4)\r\n",
        "\r\n",
        "    c5 = Dropout(0.2)(c5)\r\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal',\r\n",
        "                            padding='same', name=\"last_conv\")(c5)\r\n",
        "#fc layers\r\n",
        "\r\n",
        "    flat=Flatten()(c5)\r\n",
        "    flat=concatenate([flat,input_vector])\r\n",
        "    den = Dense(hp.Int(f'dense_base_unit',\r\n",
        "                                min_value=12,\r\n",
        "                                max_value=128,\r\n",
        "                                step=4), activation='relu')(flat)\r\n",
        "\r\n",
        "    #for i in range(hp.Int('n_layers', 1, 4)):  # adding variation of layers.\r\n",
        "\r\n",
        "\r\n",
        "      #den = Dense(hp.Int(f'conv_{i}_units',\r\n",
        "       #                         min_value=4,\r\n",
        "       #                         max_value=64,\r\n",
        "       #                         step=4), activation='relu')(den)\r\n",
        "      #den= Dropout(hp.Float(f'drop_{i}_rate',\r\n",
        "        #                        min_value=0,\r\n",
        "        #                        max_value=.5,\r\n",
        "        #                        step=.1,))(den)\r\n",
        "\r\n",
        "    classification_output = Dense(2, activation = 'sigmoid', name=\"classification_output\")(den)\r\n",
        "\r\n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\r\n",
        "\r\n",
        "    #c4 = Resizing(14,14,interpolation='nearest')(c4)\r\n",
        "    u6 = concatenate([u6, c4])\r\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',\r\n",
        "                            padding='same')(u6)\r\n",
        "    c6 = Dropout(0.2)(c6)\r\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',\r\n",
        "                            padding='same')(c6)\r\n",
        "\r\n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\r\n",
        "    #c3= Resizing(28,28,interpolation='nearest')(c3)\r\n",
        "\r\n",
        "    u7 = concatenate([u7, c3])\r\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',\r\n",
        "                            padding='same')(u7)\r\n",
        "    c7 = Dropout(0.2)(c7)\r\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',\r\n",
        "                            padding='same')(c7)\r\n",
        "\r\n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\r\n",
        "    u8 = Resizing(62,62,interpolation='nearest')(c2)\r\n",
        "\r\n",
        "    u8 = concatenate([u8, c2])\r\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',\r\n",
        "                            padding='same')(u8)\r\n",
        "    c8 = Dropout(0.2)(c8)\r\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',\r\n",
        "                            padding='same')(c8)\r\n",
        "\r\n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\r\n",
        "    #c1= Resizing(112,112,interpolation='nearest')(c1)\r\n",
        "\r\n",
        "    u9 = concatenate([u9, c1], axis=3)\r\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal',\r\n",
        "                            padding='same')(u9)\r\n",
        "    c9 = Dropout(0.2)(c9)\r\n",
        "\r\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal',\r\n",
        "                            padding='same')(c9)\r\n",
        "\r\n",
        "\r\n",
        "    decoder_out = Conv2D(1, (1, 1), activation='sigmoid',name=\"decoder_output\")(c9)\r\n",
        "\r\n",
        "    model = Model([input_tensor,input_vector], [decoder_out,classification_output])\r\n",
        "    model.compile(optimizer='adam', loss={'decoder_output':'binary_crossentropy','classification_output':'categorical_crossentropy'},\r\n",
        "                  metrics={'decoder_output':'MAE','classification_output':tf.keras.metrics.AUC()})\r\n",
        "    return model\r\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkBNZ4BXqkx_"
      },
      "source": [
        "datapath='/content/drive/MyDrive/large_sample_Im_segmented_ref'\n",
        "\n",
        "X_rad,Y_rad,LABELS_rad = read_dataset(datapath,'pgm','_2_resized','_1_resized')\n",
        "X_rad = X_rad/255\n",
        "Y_rad = Y_rad/255\n",
        "\n",
        "\n",
        "\"\"\"#In questa sezione estraiamo le feature con pyradiomics e facciamo la PCA\n",
        "\n",
        "Ora si estraggono le feature e si mettono in un dizionario che verrà poi convertito in un pandas dataframe\n",
        "\"\"\"\n",
        "\n",
        "x_id =\"_resized\"\n",
        "y_id=\"_mass_mask\"\n",
        "ext='pgm'\n",
        "fnames = glob.glob(os.path.join(datapath, f\"*{x_id}.{ext}\"))\n",
        "fnamesmask = glob.glob(os.path.join(datapath, f\"*{y_id}.{ext}\"))\n",
        "\n",
        "extractor = featureextractor.RadiomicsFeatureExtractor()\n",
        "extractor.disableAllFeatures()\n",
        "extractor.enableFeatureClassByName('gldm')\n",
        "extractor.enableFeatureClassByName('glcm')\n",
        "extractor.enableFeatureClassByName('shape2D')\n",
        "extractor.enableFeatureClassByName('firstorder')\n",
        "extractor.enableFeatureClassByName('glrlm')\n",
        "extractor.enableFeatureClassByName('glszm')\n",
        "extractor.enableFeatureClassByName('ngtdm')\n",
        "\n",
        "dataframe={f.replace(datapath,''):extractor.execute(read_pgm_as_sitk(f), read_pgm_as_sitk(f.replace(x_id,y_id)),label=255) for f in fnames}\n",
        "\n",
        "\n",
        "Pandata=pd.DataFrame(dataframe)\n",
        "\n",
        "Pandataframe=Pandata.drop(Pandata.index[0:22]).T\n",
        "\n",
        "\n",
        "X_train_rad, X_test_rad, Y_train_rad, Y_test_rad,class_train_rad,class_test_rad,feature_train,feature_test = train_test_split(X_rad, Y_rad,LABELS_rad,Pandataframe, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "sc = StandardScaler()\n",
        "feature_train = sc.fit_transform(feature_train)\n",
        "feature_test = sc.transform(feature_test)\n",
        "\n",
        "\n",
        "pca = PCA()\n",
        "feature_train = pca.fit_transform(feature_train)\n",
        "feature_test = pca.transform(feature_test)\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "\n",
        "pca = PCA(n_components=3)\n",
        "feature_train = pca.fit_transform(feature_train)\n",
        "feature_test = pca.transform(feature_test)\n",
        "\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip= True,\n",
        "        fill_mode='reflect')\n",
        "\n",
        "transform = train_datagen.get_random_transform((124,124))\n",
        "\n",
        "\n",
        "X_train_rad_tr, X_train_rad_val, Y_train_rad_tr, Y_train_rad_val,class_train_rad_tr,class_train_rad_val,feature_train_tr,feature_train_val = train_test_split(X_train_rad, Y_train_rad, to_categorical(class_train_rad,2),feature_train, test_size=0.2, random_state=24)\n",
        "\n",
        "mass_gen_rad = MassesSequence_radiomics(X_train_rad_tr, Y_train_rad_tr,class_train_rad_tr,feature_train_tr, train_datagen)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STmmHSagSeDS"
      },
      "source": [
        "tuner = BayesianOptimization(\r\n",
        "    build_model_rad_UNET,\r\n",
        "    objective= kerastuner.Objective(\"val_classification_output_auc\", direction=\"max\"),\r\n",
        "    max_trials=10,\r\n",
        "    executions_per_trial=1,\r\n",
        "    directory=LOG_DIR)\r\n",
        "\r\n",
        "tuner.search(mass_gen_rad,\r\n",
        "             verbose=2,\r\n",
        "             epochs=100,\r\n",
        "             batch_size=len(mass_gen_rad),\r\n",
        "             #callbacks=[tensorboard],\r\n",
        "             validation_data=([X_train_rad_val,feature_train_val], [Y_train_rad_val,class_train_rad_val]))\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMvBohhN69qG",
        "outputId": "eb568438-30c5-42d8-9d11-7817a650fed0"
      },
      "source": [
        "tuner.get_best_hyperparameters()[0].values\r\n",
        "\r\n",
        "newmod=build_model_rad_UNET(tuner.get_best_hyperparameters()[0])\r\n",
        "newmod.summary()\r\n",
        "\r\n",
        "tuner.get_best_models()[0].summary()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "newmod.save('model_Unet_Tuned') #the model_opt is better\r\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 124, 124, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 124, 124, 16) 160         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 124, 124, 16) 0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 124, 124, 16) 2320        dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 62, 62, 16)   0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 62, 62, 32)   4640        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 62, 62, 32)   0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 62, 62, 32)   9248        dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 31, 31, 32)   0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "resizing_3 (Resizing)           (None, 32, 32, 32)   0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 64)   18496       resizing_3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 32, 32, 64)   0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 64)   36928       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "resizing_4 (Resizing)           (None, 16, 16, 64)   0           max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "resizing_5 (Resizing)           (None, 62, 62, 32)   0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 128)  73856       resizing_4[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 62, 62, 64)   0           resizing_5[0][0]                 \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 16, 16, 128)  0           conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 62, 62, 32)   18464       concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 128)  147584      dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 62, 62, 32)   0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 128)    0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 62, 62, 32)   9248        dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 8, 8, 256)    295168      max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 124, 124, 16) 2064        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 8, 8, 256)    0           conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 124, 124, 32) 0           conv2d_transpose_7[0][0]         \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "last_conv (Conv2D)              (None, 8, 8, 256)    590080      dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 124, 124, 16) 4624        concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 16384)        0           last_conv[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 124, 124, 16) 0           conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 16387)        0           flatten_1[0][0]                  \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 124, 124, 16) 2320        dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 56)           917728      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output (Conv2D)         (None, 124, 124, 1)  17          conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "classification_output (Dense)   (None, 2)            114         dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 2,133,059\n",
            "Trainable params: 2,133,059\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 124, 124, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 124, 124, 16) 160         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 124, 124, 16) 0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 124, 124, 16) 2320        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 62, 62, 16)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 62, 62, 32)   4640        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 62, 62, 32)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 62, 62, 32)   9248        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 31, 31, 32)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "resizing (Resizing)             (None, 32, 32, 32)   0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 64)   18496       resizing[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 64)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 64)   36928       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "resizing_1 (Resizing)           (None, 16, 16, 64)   0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "resizing_2 (Resizing)           (None, 62, 62, 32)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 128)  73856       resizing_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 62, 62, 64)   0           resizing_2[0][0]                 \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 16, 16, 128)  0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 62, 62, 32)   18464       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 128)  147584      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 62, 62, 32)   0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 128)    0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 62, 62, 32)   9248        dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 8, 8, 256)    295168      max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 124, 124, 16) 2064        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 8, 8, 256)    0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 124, 124, 32) 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "last_conv (Conv2D)              (None, 8, 8, 256)    590080      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 124, 124, 16) 4624        concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 16384)        0           last_conv[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 124, 124, 16) 0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 16387)        0           flatten[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 124, 124, 16) 2320        dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 56)           917728      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output (Conv2D)         (None, 124, 124, 1)  17          conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "classification_output (Dense)   (None, 2)            114         dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 2,133,059\n",
            "Trainable params: 2,133,059\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "INFO:tensorflow:Assets written to: model_Unet_Tuned/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
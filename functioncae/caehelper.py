# -*- coding: utf-8 -*-
"""CAE_FUNCTS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11RxvQyF5oZG7Ty0AbwfHVsnBhGTxdoTV
"""

#In questo file sono riportate tutte le funzioni helper per il software. Farò in un altro i codici per i modelli
import PIL
from PIL import Image
import cv2
import os
import numpy as np
import glob
from skimage.io import imread
import time
import re

def save_newext(file_name,data_path,ext1,ext2,endpath):
  """
  Riscrive le immagini in formato leggibile per pyradiomics
  type file_name: stringa
  param file_path: nome del file della immagine

  type data_path: stringa
  param data_path: percorso della cartella dove si trova la immagine

  type ext1: stringa
  param ext1: stringa identificativa dell'estenzione di partenza della immagine

  type ext2: stringa
  param ext2: stringa identificativa dell'estenzione finale della immagine

  type endpath: stringa
  param endpath: percorso della cartella di arrivo
  """
  try:
    image=plt.imread(os.path.join(data_path,file_name))
    file_name=file_name.replace(f'.{ext1}',f'.{ext2}') #insert logging warning if ext1==ext2
  except:
    raise ValueError('immagine o path non trovati')
  status = cv2.imwrite(os.path.join(endpath,file_name),image)

  return status

def unit_masks(file_name,data_path,ext1,ext2, endpath):
  """
  Normalizza i valori dei pixel delle maschere già nei file per essere utilizzati con pyradiomics.
  Permette inoltre di cambiare l'estenzione da .pgm a .png o qualunque altra estenzione supportata.

  type file_name: stringa
  param file_path: nome del file della maschera

  type data_path: stringa
  param data_path: percorso della cartella dove si trova la maschera

  type ext1: stringa
  param ext1: stringa identificativa dell'estenzione di partenza della maschera

  type ext2: stringa
  param ext2: stringa identificativa dell'estenzione finale della maschera

  type endpath: stringa
  param endpath: percorso della cartella di arrivo
  """
  try:
    image=plt.imread(os.path.join(data_path,file_name))
  except:
    raise ValueError('immagine o path non trovati!')
  image=image/255
  file_name=file_name.replace(f'.{ext1}',f'.{ext2}')
  status = cv2.imwrite(os.path.join(endpath,file_name),image)
  return status,image

def read_dataset(dataset_path,ext,benign_label,malign_label,x_id ="_resized", y_id="_mass_mask"):
  """
  Data la cartella con le maschere e le immagini, restituisce i vettori con le immagini, le maschere e le classi.
  Restituisce i vettori come tensori da dare alla rete.

  type dataset_path: stringa
  param dataset_path: Cartella con le immagini e le relative maschere

  type data_path: stringa
  param data_path: percorso della cartella dove si trova la maschera

  type ext: stringa
  param ext: stringa identificativa dell'estenzione delle immagini e maschere

  type x_id: stringa
  param x_id: identificativo delle immagini

  type x_id: stringa
  param x_id: identificativo delle maschere

  type benign_label: stringa
  param benign_label: identificativo delle masse benigne

  type malign_label: stringa
  param malign_label: identificativo delle masse maligne

  """

  fnames = glob.glob(os.path.join(dataset_path, f"*{x_id}.{ext}"))
  if fnames == []:
    raise Exception('Niente immagini! Il path è sbagliato, magari x_id o ext sono sbagliati! ')
  else:
    pass
  X = []
  Y = []
  class_labels=[]
  for fname in fnames:
      X.append(plt.imread(fname)[1:,1:,np.newaxis])
      Y.append(plt.imread(fname.replace(x_id, y_id))[1:,1:,np.newaxis])
      if benign_label in fname:
        class_labels.append(0)
      elif malign_label in fname:
        class_labels.append(1)
  return np.array(X), np.array(Y) , np.array(class_labels)

def read_dataset_big(dataset_path_mass,dataset_path_mask,benign_label,malign_label,ext='png',resize=False):
  """
  Versione di read_dataset per il dataset del TCIA.
  Data la cartella con le maschere e le immagini, restituisce i vettori con i filepath delle immagini, le maschere e le classi.
  Restituisce i vettori come tensori da dare al generatore per la rete.

  type dataset_path_mass: stringa
  param dataset_path_mass: Cartella con le immagini

  type dataset_path_mask: stringa
  param dataset_path_mask: percorso della cartella dove si trovano le maschera

  type ext: stringa
  param ext: stringa identificativa dell'estenzione delle immagini e maschere

  type resize: bool
  param resize: Se TRUE fa il reshape delle maschere per combaciare con quello delle immagini



  """
  fnames  = glob.glob(os.path.join(dataset_path_mass, f"*.{ext}"))
  if fnames == []:
    raise Exception('Niente immagini! Il path è sbagliato, magari ext è sbagliato! ')
  else:
    pass
  masknames = glob.glob(os.path.join(dataset_path_mask, f"*.{ext}"))
  if masknames==[]:
    raise Exception('Immagini o path non trovati!')
  else:
    pass
  X = []
  Y = []
  class_labels=[]
  for fname in fnames:
    try:
      assert(fname.replace(dataset_path_mass, dataset_path_mask) in masknames)
    except:
      raise Exception('Non vi è corrispondenza tra i nomi delle immagini e quelle delle maschere')
    Y.append(fname.replace(dataset_path_mass, dataset_path_mask))
    X.append(fname)
    if resize == True:
      X_image=imread(fname)
      Y_image=imread(fname.replace(dataset_path_mass, dataset_path_mask))
      image=np.array(Image.fromarray(Y_image).resize(size=(X_image.shape[1],X_image.shape[0])))
      cv2.imwrite(fname.replace(dataset_path_mass, dataset_path_mask),image)

    if benign_label in fname:
      class_labels.append(0)
    elif malign_label in fname:
      class_labels.append(1)


  return np.array(X), np.array(Y) , np.array(class_labels)

import pickle
import SimpleITK as sitk
import radiomics
from radiomics import featureextractor

def radiomic_dooer(list_test,datapath,endpath,lab,extrc):

  """
  Funzione per estrarre le feature con pyradiomics e salvarle in un dizionario.

  type list_test: lista
  param list_test: lista con path immagine e relativa maschera normalizzata

  type datapath: stringa
  param datapath: percorso cartella dove si trova l'immagine

  type endpath: stringa
  param endpath: cartella dove si salva il pickle del dizionario

  type resize: bool
  param resize: Se TRUE fa il reshape delle maschere per combaciare con quello delle immagini



  """
  b=time.perf_counter()
  #try:
  info=extrc.execute(list_test[0],list_test[1],lab)
  #except:
    #raise Exception('Problema con pyradiomics: forse vi è un problema col label o i path. Controlla che pyradiomics sia installato e che da radiomics sia importato featureextractor')
  c=time.perf_counter()
  print(f'time to extract:{c-b}')#sostituisci con logging
  d=time.perf_counter()
  pattern=re.compile('P_0\d*_[A-Z]*_[A-Z]*_[A-Z]*')
  name=re.findall(pattern,list_test[0])
  dict_r={name[0]:info}
  #try:
  with open(os.path.join(endpath,f'feats_{name[0]}.pickle'), 'wb') as handle:
    pickle.dump(dict_r, handle, protocol=pickle.HIGHEST_PROTOCOL)
  #except:
  #  raise Exception('Qualcosa è andato male nel definire il path di arrivo, controlla che endpath sia giusto')
  del(dict_r)
  print(f'time to update:{d-c}') #substitute with logging

  return name

def read_pgm_as_sitk(image_path):
  """ Read a pgm image as sitk image """
  np_array = np.asarray(PIL.Image.open(image_path))
  sitk_image = sitk.GetImageFromArray(np_array)
  return sitk_image

def dict_update_radiomics(data_path,dictionary):

  """
  Funzione per unire i vari dizionari creati con radiomic_dooer per poi creare il dataframe

  type data_path: stringa (.pickle)
  param data_path: percorso del pickle da aprire

  type dictionary: dizionario
  param dictionary: dizionario generale del dataframe

  """
  with open(data_path, 'rb') as handle:
    b = pickle.load(handle)
    dictionary.update(b)

  return(dictionary)

def blender(img1,img2,a,b):
  """
  Funzione per sovraimporre due immagini con sfumatura

  type img1: array numpy
  param img1: immagine da sovrapporre
  type img2: array numpy
  param img2: immagine da svrapporre
  type a: int or float
  param a: valore di sfumatura di img1
  type b: int or float
  param b: valore di sfumatura di img2
  """
  try:
    image=cv2.addWeighted(img1,a, img2, b,0)
  except:
    raise Exception('Sovrapposizione non riuscita. Controllare che le immagini siano giuste e che a e b siano numeri.')

  return  image

def dice(pred, true, k = 1):
  """
    Funzione per calcolare l'indice di Dice

    type pred: array numpy
    param pred: immagini predette dal modello

    type true : array numpy
    param true: immagini target

    type k : int
    param k: valore pixel true della maschera
  """

  intersection = np.sum(pred[true==k]) * 2.0
  dice = intersection / (np.sum(pred) + np.sum(true))
  return dice

def dice_vectorized(pred, true, k = 1):
  """
    Versione vettorizzata per calcolare il coefficiente di dice
    type pred: array numpy
    param pred: immagini predette dal modello

    type true : array numpy
    param true: immagini target

    type k : int
    param k: valore pixel true della maschera
  """
  intersection = 2.0 *np.sum(pred * (true==k), axis=(1,2,3))
  dice = intersection / (pred.sum(axis=(1,2,3)) + true.sum(axis=(1,2,3)))
  return dice

import matplotlib.pyplot as plt
def modelviewer(model):
  """
  Funzione per visualizzare l'andamento della loss di training e validazione per l'autoencoder e per il classificatore
    type model:  model.fit()
    param model: history del modello di Keras ottenuto dalla funzione
  """

  plt.figure('modelviewer')
  plt.subplot(2,1,1)
  plt.title('autoencoder')
  try:
    plt.plot(model.history['decoder_output_loss'])
    plt.plot(model.history['val_decoder_output_loss'])
  except:
    raise Exception('Attenzione, o model non è un modello Keras o il modello non ha i campi decoder_output_loss o val_decoder_output_loss')
  plt.legend(['loss', 'val_loss'])
  plt.subplot(2,1,2)
  plt.title('classifier')
  try:
    plt.plot(model.history['classification_output_loss'])
    plt.plot(model.history['val_classification_output_loss'])
  except:
    raise Exception('Attenzione, il modello non ha i campi classification_output_loss o val_classification_output_loss')
  plt.legend(['loss', 'val_loss'])
  plt.show()
  return

import tensorflow as tf

def heatmap(x,model):
  """
  Funzione che mostra la heatmap dell'ultimo layer convoluzionale prima del classificatore senza funzionalità radiomiche
    type x: array numpy
    param x: immagine da segmentare

    type model : keras model
    param model: modello allenato
  """
  img_tensor =x[np.newaxis,...]
  preds = model.predict(img_tensor)[1]
  argmax = np.argmax(preds)
  conv_layer = model.get_layer("last_conv")
  heatmap_model = models.Model([model.inputs], [conv_layer.output, model.output])

  # Get gradient of the winner class w.r.t. the output of the (last) conv. layer
  with tf.GradientTape() as gtape:
      conv_output, predictions = heatmap_model(img_tensor)
      loss = predictions[1][:, np.argmax(predictions[1])]
      grads = gtape.gradient(loss, conv_output)
      pooled_grads = K.mean(grads, axis=(0, 1, 2))

  heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)
  heatmap = np.maximum(heatmap, 0)
  max_heat = np.max(heatmap)
  if max_heat == 0:
      max_heat = 1e-10
  heatmap /= max_heat


  plt.matshow(heatmap.squeeze())
  plt.show()

  x = np.asarray(255*x, np.uint8)
  heatmap = np.asarray(255*heatmap.squeeze(), np.uint8)


  heatmap = cv2.resize(heatmap, (x.shape[1], x.shape[0]))



  plt.imshow(blender(x,heatmap,1,1))
  plt.axis('off')
  if argmax==1:
    plt.title('the mass is malign')
  else:
    plt.title('the mass is benign')

  return heatmap

import tensorflow as tf
from tensorflow.python.keras import backend as K
from tensorflow.keras import models

def heatmap_rad(x,feature,model):
  """
  Funzione che mostra la heatmap dell'ultimo layer convoluzionale prima del classificatore con funzionalità radiomiche
    type x: array numpy
    param x: immagine da segmentare

    type feature: array numpy
    param feature:feature estratte con pyradiomics

    type model : keras model
    param model: modello allenato
  """
  img_tensor =x[np.newaxis,...]
  feature_tensor=feature[np.newaxis,...]
  preds = model.predict([img_tensor,feature_tensor])[1]
  argmax = np.argmax(preds)
  conv_layer = model.get_layer("last_conv")
  heatmap_model = models.Model([model.inputs], [conv_layer.output, model.output])

  # Get gradient of the winner class w.r.t. the output of the (last) conv. layer
  with tf.GradientTape() as gtape:
      conv_output, predictions = heatmap_model([img_tensor,feature_tensor])
      loss = predictions[1][:, np.argmax(predictions[1])]
      grads = gtape.gradient(loss, conv_output)
      pooled_grads = K.mean(grads, axis=(0, 1, 2))

  heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)
  heatmap = np.maximum(heatmap, 0)
  max_heat = np.max(heatmap)
  if max_heat == 0:
      max_heat = 1e-10
  heatmap /= max_heat

  plt.figure('heatmap')
  plt.matshow(heatmap.squeeze())
  plt.show()

  x = np.asarray(255*x, np.uint8)
  heatmap = np.asarray(255*heatmap.squeeze(), np.uint8)


  heatmap = cv2.resize(heatmap, (x.shape[1], x.shape[0]))

  plt.figure('Heatactivation')
  plt.imshow(blender(x,heatmap,1,1))
  plt.axis('off')
  if argmax==1:
    plt.title('the mass is malign')
  else:
    plt.title('the mass is benign')
  plt.show()
  return heatmap

def plot_roc_curve(fper, tper,auc):
  """
  Funzione che fa il plot della curva roc
  type fper: float
  param fper: percentuale falsi positivi

  type tper: float
  param tper:percentuale veri positivi

  """
  plt.figure('AUC')
  plt.plot(fper, tper, color='orange', label='ROC')
  plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')
  plt.xlabel('False Positive Rate')
  plt.ylabel('True Positive Rate')
  plt.title('Receiver Operating Characteristic (ROC) Curve with AUC = %.2f'%auc)
  plt.legend()
  plt.show()

from skimage.filters import threshold_multiotsu

def otsu(image,n_items=2):
  """
  Funzione che implementa l'algoritmo di Otsu per la segmentazione
    type image: numpy array
    param fper: immagine da segmentare

    type n_items: intero
    param n_items:numero di oggetti da segmentare nell'immagine

  """
  thresholds = threshold_multiotsu(image,classes=n_items)
  regions = np.digitize(image, bins=thresholds)
  return regions
# -*- coding: utf-8 -*-
"""AutoencoderV2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Rpy1Zyyq_mG72N44JJdTWGULzR1oaRfJ

# Load the data from drive
"""

from google.colab import drive #remember to add the features from the data if you can load it correctly
drive.mount('/content/drive')

imagepath='/content/drive/My Drive/large_sample_Im_segmented_ref/0003s1_1_1_1_resized.pgm'
masspath='/content/drive/My Drive/large_sample_Im_segmented_ref/0003s1_1_1_1_mass_mask.pgm'

"""# Let's look at the sample data"""

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
img = mpimg.imread(masspath)
img2 = mpimg.imread(imagepath)
plt.figure(figsize=(14,4))
plt.subplot(1,2,2)
plt.title('image')
plt.imshow(img2)
plt.subplot(1,2,1)
plt.title('real mass')
plt.imshow(img)
plt.show()

"""#Let's load the data to our image and mask image vectors"""

import glob
import math
import os
import numpy as np


from skimage.io import imread

dataset_path='/content/drive/My Drive/large_sample_Im_segmented_ref'

benign_label_mass='_2_mass'
malign_label_mass='_1_mass'

benign_label_mask='_2_resized'
malign_label_mask='_1_resized'

endpath='/content/drive/My Drive/GoodPNGMassesV2'

#os.mkdir(endpath)

import cv2
x_id ="_resized"
y_id="_mass_mask"
for f in glob.glob(dataset_path+'/*'):
  try: 
    image=plt.imread(f)
    if x_id in f:
      image=image
    elif y_id in f:
      image=image/255
    else:
      print('error, no mask or mass files')
    f=f.replace('.pgm','.png')
    f=f.replace('/content/drive/My Drive/large_sample_Im_segmented_ref/','')

    status = cv2.imwrite(os.path.join(endpath,f),image)
  except:
    pass

def read_dataset(dataset_path,ext, x_id ="_resized", y_id="_mass_mask"):
    fnames = glob.glob(os.path.join(dataset_path, f"*{x_id}.{ext}"  ))
    X = []
    Y = []
    class_labels=[]
    for fname in fnames:
        X.append(imread(fname)[1:,1:,np.newaxis])
        Y.append(imread(fname.replace(x_id, y_id))[1:,1:,np.newaxis])
        if benign_label_mass in fname or benign_label_mask in fname:
          class_labels.append(0)
        elif malign_label_mass in fname or malign_label_mask in fname:
          class_labels.append(1)
    return np.array(X), np.array(Y) , np.array(class_labels)

X_rad,Y_rad,LABELS_rad = read_dataset(endpath,'png')

X,Y,LABELS = read_dataset(dataset_path,'pgm')

X_rad.shape,X_rad.max(),X_rad.min()

print(X.shape, Y.shape)
print(X.min(), X.max(), Y.min(), Y.max())

X = X/255
Y = Y/255
X_rad = X_rad/255
Y_rad.min(),Y_rad.max()

from keras.utils import to_categorical

# Change the labels from categorical to one-hot encoding
LABELS_cat = to_categorical(LABELS,2)

"""We split the dataset in a train and a test sets. """

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test,class_train,class_test = train_test_split(X, Y,LABELS, test_size=0.2, random_state=42)

print(X_train.shape, X_test.shape,class_train.shape,class_test.shape)

plt.imshow(X_rad[67].squeeze())

"""#PyRadiomics!!!

"""

!pip install pyradiomics

from __future__ import print_function
import SimpleITK as sitk

import six
import os  # needed navigate the system to get the input data

import radiomics
from radiomics import featureextractor  # This module is used for interaction with pyradiomics
x_id ="_resized"
y_id="_mass_mask"
ext='png'
fnames = glob.glob(os.path.join(endpath, f"*{x_id}.{ext}"))
fnamesmask = glob.glob(os.path.join(endpath, f"*{y_id}.{ext}"))

extractor = featureextractor.RadiomicsFeatureExtractor()
#print(extractor.enabledFeatures)
extractor.disableAllFeatures()
extractor.enableFeatureClassByName('firstorder')
extractor.enableFeatureClassByName('glcm')
extractor.enableFeatureClassByName('gldm')
extractor.enableFeatureClassByName('glrlm')
extractor.enableFeatureClassByName('glszm')
extractor.enableFeatureClassByName('ngtdm')
extractor.enableFeatureClassByName('shape')

dataframe={f.replace(endpath,''):extractor.execute(f, f.replace(x_id,y_id)) for f in fnames}


#result = extractor.execute(fnames[0], fnames[0].replace(x_id,y_id))

#print('Result type:', type(result))  # result is returned in a Python ordered dictionary)
#print('')
#print('Calculated features')
#for key, value in six.iteritems(result):
#    print('\t', key, ':', value)

import pandas as pd

Pandata=pd.DataFrame(dataframe)

Pandata

Pandata.index

for i,name in enumerate(Pandata.index):
  if 'diagnostics' in Pandata.index[i]:
    print(i)  
  else:
    pass

Pandataframe=Pandata.drop(Pandata.index[0:22]).T

Pandataframe

"""Now that we have all our features, let's do the PCA"""

X_train_rad, X_test_rad, Y_train_rad, Y_test_rad,class_train_rad,class_test_rad,feature_train,feature_test = train_test_split(X_rad, Y_rad,LABELS_rad,Pandataframe, test_size=0.2, random_state=42)

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
feature_train = sc.fit_transform(feature_train)
feature_test = sc.transform(feature_test)

from sklearn.decomposition import PCA

pca = PCA()
feature_train = pca.fit_transform(feature_train)
feature_test = pca.transform(feature_test)
explained_variance = pca.explained_variance_ratio_

explained_variance

percentage_var_explained = pca.explained_variance_ratio_;  
cum_var_explained=np.cumsum(percentage_var_explained)
#plot PCA spectrum   
plt.figure(1,figsize=(6,4))
plt.clf()  
plt.plot(cum_var_explained,linewidth=2)  
plt.axis('tight')  
plt.grid() 
plt.xlabel('n_components') 
plt.ylabel('Cumulative_Variance_explained')  
plt.show()

# look at explainded variance of PCA components 
exp_var_cumsum=pd.Series(np.round(pca.explained_variance_ratio_.cumsum(),4)*100)  
for index,var in enumerate(exp_var_cumsum):  
    print('if n_components= %d,   variance=%f' %(index,np.round(var,3)))

from sklearn.decomposition import PCA

pca = PCA(n_components=3) #voglio che il numero di componenti descriva il 95% della varianza
feature_train = pca.fit_transform(feature_train)
feature_test = pca.transform(feature_test)

"""#Let's load the bigger data - NOT USED data weird shape"""

import os
import glob
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image


datapath='/content/drive/MyDrive/Mass_data_New'
train='TRAINING'
test='TESTING'
mass_train='Train_data'
mass_test='Test_data'
mask_train='mask_train_resized'
mask_test='mask_test_resized'
benign_label='BENIGN'
malign_label='MALIGNANT'

masks_1=os.path.join(datapath,train,mask_train)
masks_2=os.path.join(datapath,test,mask_test)

masks_2

#os.mkdir(os.path.join(datapath,train,'mask_tr_V2'))
#os.mkdir(os.path.join(datapath,test,'mask_test_V2'))

import cv2 #these kind of functions can be implemented in multithreading
#This function is to use to normalize the mask from the file because pyradiomics
#needs a filemask that is max 1 and min 0
#don't need to run it everytime
def mask_unit(path_in,path_out):
  for f in glob.glob(path_in+'/*.png'):
    image=imread(f)
    image=image/255
    g=f.replace(path_in+'/','')
    status = cv2.imwrite(os.path.join(path_out,g),image)

masks_1

#mask_unit(masks_1,os.path.join(datapath,train,'mask_tr_V2'))

mask_unit('/content/drive/MyDrive/Mass_data_New/TESTING/mask_test_resized',os.path.join(datapath,test,'mask_test_V2'))

def read_dataset_big(dataset_path_mass,dataset_path_mask,ext='png'):
  #this function loads the datapaths in arrays, the commented part is to make mask and data same size 
    fnames = glob.glob(os.path.join(dataset_path_mass, f"*.{ext}"))
    masknames = glob.glob(os.path.join(dataset_path_mask, f"*.{ext}"))
    X = []
    Y = []
    class_labels=[]
    for fname in fnames:
      try:
        assert(fname.replace(dataset_path_mass, dataset_path_mask) in masknames)
        Y.append(fname.replace(dataset_path_mass, dataset_path_mask))
        X.append(fname)
        #X_image=imread(fname)
        #Y_image=imread(fname.replace(dataset_path_mass, dataset_path_mask))
        #image=np.array(Image.fromarray(Y_image).resize(size=(X_image.shape[1],X_image.shape[0])))
        #cv2.imwrite(fname.replace(dataset_path_mass, dataset_path_mask),image)
        #np.delete(X_image)
        #np.delete(Y_image)
        if benign_label in fname:
          class_labels.append(0)
        elif malign_label in fname:
          class_labels.append(1)
      except:
        pass
          
    return np.array(X), np.array(Y) , np.array(class_labels)

X_big_train,Y_big_train,Class_big_train=read_dataset_big(os.path.join(datapath,train,mass_train)
,os.path.join(datapath,train,'mask_tr_V2'))

X_big_test,Y_big_test,Class_big_test=read_dataset_big(os.path.join(datapath,test,mass_test)
,os.path.join(datapath,test,'mask_test_V2'))

#just a test
plt.imshow(imread(X_big_test[0]))
print(X_big_test[0],Y_big_test[0])
#print(imread(X_big_train[0]).shape,np.array(Image.fromarray(imread(Y_big_train[0])).resize(size=(imread(X_big_train[0]).shape))).shape)
plt.figure()
plt.imshow(np.array(Image.fromarray(imread(Y_big_train[0])).resize(size=(1538,2047))))

"""#Pyradiomics on big dataset"""

!pip install pyradiomics

from __future__ import print_function
import SimpleITK as sitk

import six
import os  # needed navigate the system to get the input data

import radiomics
from radiomics import featureextractor  # This module is used for interaction with pyradiomics

#os.mkdir('/content/drive/My Drive/radiomic_feats_big_test')

import radiomics #this function extracts the features from a single image, to use
#with multiprocessing
from radiomics import featureextractor
import time
import pickle
featpath='/content/drive/My Drive/radiomic_feats_big_TEST'
extractor = featureextractor.RadiomicsFeatureExtractor()

def radiomic_dooer_test(list_test):
  a=time.perf_counter()
  image = sitk.ReadImage(list_test[0], imageIO="PNGImageIO")
  mask = sitk.ReadImage(list_test[1], imageIO="PNGImageIO")
  b=time.perf_counter()
  print(f'time to read:{b-a}')
  info=extractor.execute(image,mask)
  c=time.perf_counter()
  print(f'time to extract:{c-b}')
  del(mask)
  del(image)
  d=time.perf_counter()
  name=list_test[0].replace('/content/drive/MyDrive/Mass_data_New/TESTING/Test_data/','')
  name=name.replace('.png','')
  dict_r={list_test[0]:info}
  with open(f'/content/drive/My Drive/radiomic_feats_big_test/feats_{name}.pickle', 'wb') as handle:
    pickle.dump(dict_r, handle, protocol=pickle.HIGHEST_PROTOCOL)  
  del(name)
  del(dict_r)                                                    #each dict in a file then 
                                                    #put everything in a csv table
  print(f'time to update:{d-c}')

  return 'one image done!'

biggy=[[X_big_train[i],Y_big_train[i]] for i in range(len(X_big_train))] 
biggy_test=[[X_big_test[i],Y_big_test[i]] for i in range(len(X_big_test))] 

#this is the filename list for the multiprocessing

import concurrent.futures

extractor = featureextractor.RadiomicsFeatureExtractor()

a1=time.perf_counter()

#trainlist=[[X_big_train[i],Y_big_train[i]] for i in range(len(X_big_train))] 
with concurrent.futures.ThreadPoolExecutor() as executor:
  executor.map(radiomic_dooer_test, 
               biggy_test)
b1=time.perf_counter()
print(f'time spent:{b-a}')

dataframe_big_train={}

def dict_update_radiomics(data_path,remove_string,dictionary):
  with open(data_path, 'rb') as handle:
    b = pickle.load(handle)
    dictionary.update(b)
    del(b)

for f in glob.glob('/content/drive/MyDrive/radiomic_feats_big/*.pickle'):
  dict_update_radiomics(f,'/content/drive/MyDrive/radiomic_feats_big',dataframe_big_train)

dataframe_big_train

import pandas as pd

Pandata_big=pd.DataFrame(dataframe_big_train)

Pandata_big.index

for i,name in enumerate(Pandata_big.index):
  if 'diagnostics' in Pandata_big.index[i]:
    print(i)  
  else:
    pass

Pandatabigframe=Pandata_big.drop(Pandata_big.index[0:22]).T

Pandatabigframe

"""Now that we have all our features, let's do the PCA"""

filesinfeat=next(os.walk('/content/drive/MyDrive/radiomic_feats_big'))[2]

filesnew_train=[]
masknew_train=[]
for f in filesinfeat:
  f=f.replace('feats_','')
  filesnew_train.append(os.path.join('/content/drive/MyDrive/Mass_data_New/TRAINING/Train_data',f.replace('pickle','png')))
  masknew_train.append(os.path.join('/content/drive/MyDrive/Mass_data_New/TRAINING/mask_tr_V2',f.replace('pickle','png')))

X_big_train=np.asarray(X_big_train)[np.in1d(X_big_train, filesnew_train)]
Y_big_train=np.asarray(Y_big_train)[np.in1d(Y_big_train, masknew_train)]

Class_big_train=[]
for fname in X_big_train:
  if benign_label in fname:
    Class_big_train.append(0)
  elif malign_label in fname:
    Class_big_train.append(1)
  else:
    print('lol')

len(Class_big_train)

X_train_rad_big, X_test_rad_big, Y_train_rad_big, Y_test_rad_big,class_train_rad_big,class_test_rad_big,feature_train_big,feature_test_big = train_test_split(X_big_train, Y_big_train,Class_big_train,Pandatabigframe, test_size=0.2, random_state=42)

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
feature_train_bigg = sc.fit_transform(feature_train_big)
feature_test_bigg = sc.transform(feature_test_big)

from sklearn.decomposition import PCA

pca = PCA()
feature_train_bigg = pca.fit_transform(feature_train_bigg)
feature_test_bigg = pca.transform(feature_test_bigg)
explained_variance_big = pca.explained_variance_ratio_

explained_variance_big

percentage_var_explained = pca.explained_variance_ratio_;  
cum_var_explained=np.cumsum(percentage_var_explained)
#plot PCA spectrum   
plt.figure(1,figsize=(6,4))
plt.clf()  
plt.plot(cum_var_explained,linewidth=2)  
plt.axis('tight')  
plt.grid() 
plt.xlabel('n_components') 
plt.ylabel('Cumulative_Variance_explained')  
plt.show()

# look at explainded variance of PCA components 
exp_var_cumsum=pd.Series(np.round(pca.explained_variance_ratio_.cumsum(),4)*100)  
for index,var in enumerate(exp_var_cumsum):  
    print('if n_components= %d,   variance=%f' %(index,np.round(var,3)))

from sklearn.decomposition import PCA

pca = PCA(n_components=3) #voglio che il numero di componenti descriva il 95% della varianza
feature_train_bigg = pca.fit_transform(feature_train_bigg)
feature_test_bigg = pca.transform(feature_test_bigg)

"""#Data augmentation big dataset"""

feature_train_bigg.shape

from keras.preprocessing.image import ImageDataGenerator
from sklearn.utils import shuffle

train_datagen = ImageDataGenerator(
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        vertical_flip= True,
        fill_mode='reflect')

transform = train_datagen.get_random_transform((124,124)) #to try with the pretrained model in https://www.datacamp.com/community/tutorials/autoencoder-classifier-python
# I can fix the seed in get_random_transform so i can make two MassSequence classes, one for generating the train and masks, one for the classification label.
transform
#x = train_datagen.apply_transform(im, transform)
#y = train_datagen.apply_transform(label, transform)

import keras
from skimage.transform import resize

class MassesSequence_radiomics_big(keras.utils.Sequence):
    """ Data augmentation class for a CAE """
    #this class is the same as the radiomics one but it also loads the images and resizes them 
    #as 4096x3072
    #ideally i want this to load the images every batch, yeld them and then delete them 

    def __init__(self, x, y,label_array,features, img_gen, batch_size=5, shape=(2048, 1536)):
        """ Initialize the sequence

        Parameters:

        x (np.array): image paths
        y (np.array): mask paths
        label_array (np.array): classification labels
        features (np.array): feature array after pca
        batch_size (int): batch size
        img_gen (ImageDatagenerator): a Keras ImageDataGenerator instance
        shape (tuple): image shape. Default (4096, 3072)

        """
        self.x, self.y,self.label_array,self.features = x, y,label_array,features
        self.shape = shape
        self.img_gen = img_gen
        self.batch_size = batch_size


    def __len__(self):
        return len(self.x) // self.batch_size

    def on_epoch_end(self):
        """Shuffle the dataset at the end of each epoch."""
        self.x, self.y ,self.label_array,self.features= shuffle(self.x, self.y,
                                                                self.label_array,self.features)

    def process(self, img, transform):
        """ Apply a transformation to an image """
        img = self.img_gen.apply_transform(img, transform)
        return img
            
    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_label_array = self.label_array[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_features = self.features[idx * self.batch_size:(idx + 1) * self.batch_size]

        X=[];
        Y=[];
        Classes=[];
        Features=[]
        
        for image, mask,label,feature in zip(batch_x, batch_y,batch_label_array,batch_features):          
            transform = self.img_gen.get_random_transform(self.shape)
            X_el=resize(imread( str(image)), (1024, 768, 1))
            Y_el=resize(imread( str(mask)), (1024, 768, 1))
            X.append(self.process(X_el, transform))
            del(X_el)
            Y.append(self.process(Y_el, transform))
            del(Y_el)
            Classes.append(label)
            Features.append(feature)
       
        return [np.array(X)/255,np.asarray(Features,np.float64)], [np.array(Y) ,np.asarray(Classes,np.float)]

        #return np.array([resize(imread( str(file_name)), (4096, 3072, 1))
        #                  for file_name in batch_x])/255.0, np.array([resize(imread( str(file_name)), (4096, 3072, 1))
        #                  for file_name in batch_x])

X_train_rad_big_tr, X_train_rad_big_val, Y_train_rad_big_tr, Y_train_rad_big_val,class_train_rad_big_tr,class_train_rad_big_val,feature_train_big_tr,feature_train_big_val = train_test_split(X_train_rad_big, Y_train_rad_big, to_categorical(class_train_rad_big,2),feature_train_bigg, test_size=0.2, random_state=24)

mass_gen_rad_big = MassesSequence_radiomics_big(X_train_rad_big_tr, Y_train_rad_big_tr,class_train_rad_big_tr,feature_train_big_tr, train_datagen)

batch=mass_gen_rad_big[67]

del(batch)

batch[0][0].shape

plt.imshow(batch[1][0][1].squeeze())

"""Now we need to create also a class to generate the validation data

"""

class Validator_Generator(keras.utils.Sequence) :
  
    def __init__(self, x, y,label_array,features, batch_size=5, shape=(2048, 1536)):
        """ Initialize the sequence for validation generation

        Parameters:

        x (np.array): image paths
        y (np.array): mask paths
        label_array (np.array): classification labels
        features (np.array): feature array after pca
        batch_size (int): batch size
        shape (tuple): image shape. Default (4096, 3072)

        """
        self.x, self.y,self.label_array,self.features = x, y,label_array,features
        self.shape = shape
        self.batch_size = batch_size
    
    def __len__(self):
      return len(self.x) // self.batch_size

  
    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_label_array = self.label_array[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_features = self.features[idx * self.batch_size:(idx + 1) * self.batch_size]

        X=[];
        Y=[];
        Classes=[];
        Features=[]
        
        for image, mask,label,feature in zip(batch_x, batch_y,batch_label_array,batch_features):          
            
            X_el=resize(imread( str(image)), (1024, 768, 1))
            Y_el=resize(imread( str(mask)), (1024, 768, 1))
            X.append(X_el)
            del(X_el)
            Y.append(Y_el)
            del(Y_el)
            Classes.append(label)
            Features.append(feature)
       
        return [np.array(X)/255,np.asarray(Features,np.float64)], [np.array(Y) ,np.asarray(Classes,np.float)]

Validation_data=Validator_Generator(X_train_rad_big_val, Y_train_rad_big_val,class_train_rad_big_val,feature_train_big_val)

"""# Data augmentation(no Pyradiomics features)

We can use the Keras ImageDataGenerator class
"""

from keras.preprocessing.image import ImageDataGenerator
from sklearn.utils import shuffle

train_datagen = ImageDataGenerator(
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        vertical_flip= True,
        fill_mode='reflect')

transform = train_datagen.get_random_transform((124,124)) #to try with the pretrained model in https://www.datacamp.com/community/tutorials/autoencoder-classifier-python
# I can fix the seed in get_random_transform so i can make two MassSequence classes, one for generating the train and masks, one for the classification label.
transform
#x = train_datagen.apply_transform(im, transform)
#y = train_datagen.apply_transform(label, transform)

"""we try a new data augmentation to fux the label problem

"""

import keras
class MassesSequence(keras.utils.Sequence):
    """ Data augmentation class for a CAE """

    def __init__(self, x, y,label_array, img_gen, batch_size=10, shape=(124,124)):
        """ Initialize the sequence

        Parameters:

        x (np.array): images
        y (np.array): masks
        label_array (np.array): classification labels
        batch_size (int): batch size
        img_gen (ImageDatagenerator): a Keras ImageDataGenerator instance
        shape (tuple): image shape. Default (124, 124)

        """
        self.x, self.y,self.label_array = x, y,label_array
        self.shape = shape
        self.img_gen = img_gen
        self.batch_size = batch_size


    def __len__(self):
        return len(self.x) // self.batch_size

    def on_epoch_end(self):
        """Shuffle the dataset at the end of each epoch."""
        self.x, self.y ,self.label_array= shuffle(self.x, self.y,self.label_array)

    def process(self, img, transform):
        """ Apply a transformation to an image """
        img = self.img_gen.apply_transform(img, transform)
        return img
            
    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_label_array = self.label_array[idx * self.batch_size:(idx + 1) * self.batch_size]

        X=[];
        Y=[];
        Classes=[];
        
        for image, mask,label in zip(self.x, self.y,self.label_array):
            transform = self.img_gen.get_random_transform(self.shape)
            X.append(self.process(image, transform))
            Y.append(self.process(mask, transform)>0.2)
            Classes.append(label)
            

          
        return np.asarray(X,np.float64), [np.asarray(Y,np.float64) ,np.asarray(Classes,np.float)]

"""We have at this time to manually split the Train dataset in a Train_tr and a Train_val dataset in order to use an internal validation set during the model.fit. 

We then augment only the Train_tr set and use the Train_val dataset as it is.
"""

X_train_tr, X_train_val, Y_train_tr, Y_train_val,class_train_tr,class_train_val = train_test_split(X_train, Y_train, to_categorical(class_train,2), test_size=0.2, random_state=24)

mass_gen = MassesSequence(X_train_tr, Y_train_tr,class_train_tr, train_datagen)

batch_old=mass_gen[6]

batch_old[0].shape

"""# Data augmentation(with Pyradiomics features)"""

import keras
class MassesSequence_radiomics(keras.utils.Sequence):
    """ Data augmentation class for a CAE """

    def __init__(self, x, y,label_array,features, img_gen, batch_size=10, shape=(124,124)):
        """ Initialize the sequence

        Parameters:

        x (np.array): images
        y (np.array): masks
        label_array (np.array): classification labels
        features (np.array): feature array after pca
        batch_size (int): batch size
        img_gen (ImageDatagenerator): a Keras ImageDataGenerator instance
        shape (tuple): image shape. Default (124, 124)

        """
        self.x, self.y,self.label_array,self.features = x, y,label_array,features
        self.shape = shape
        self.img_gen = img_gen
        self.batch_size = batch_size


    def __len__(self):
        return len(self.x) // self.batch_size

    def on_epoch_end(self):
        """Shuffle the dataset at the end of each epoch."""
        self.x, self.y ,self.label_array,self.features= shuffle(self.x, self.y,
                                                                self.label_array,self.features)

    def process(self, img, transform):
        """ Apply a transformation to an image """
        img = self.img_gen.apply_transform(img, transform)
        return img
            
    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_label_array = self.label_array[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_features = self.features[idx * self.batch_size:(idx + 1) * self.batch_size]


        X=[];
        Y=[];
        Classes=[];
        Features=[]
        
        for image, mask,label,feature in zip(self.x, self.y,self.label_array,self.features):
            transform = self.img_gen.get_random_transform(self.shape)
            X.append(self.process(image, transform))
            Y.append(self.process(mask, transform)>0.2)
            Classes.append(label)
            Features.append(feature)

          
        return [np.asarray(X,np.float64),np.asarray(Features,np.float64)], [np.asarray(Y,np.float64) ,np.asarray(Classes,np.float)]

X_train_rad_tr, X_train_rad_val, Y_train_rad_tr, Y_train_rad_val,class_train_rad_tr,class_train_rad_val,feature_train_tr,feature_train_val = train_test_split(X_train_rad, Y_train_rad, to_categorical(class_train,2),feature_train, test_size=0.2, random_state=24)

feature_train_tr.shape,feature_train_val.shape

mass_gen_rad = MassesSequence_radiomics(X_train_rad_tr, Y_train_rad_tr,class_train_rad_tr,feature_train_tr, train_datagen)

"""#Helper functions

"""

import cv2
import matplotlib.image as mpimg
from keras import backend as K
import cv2
def blender(img1,img2,a,b):
  return  cv2.addWeighted(img1,a, img2, b,0)

def dice(pred, true, k = 1):
    intersection = np.sum(pred[true==k]) * 2.0
    dice = intersection / (np.sum(pred) + np.sum(true))
    return dice

def dice_vectorized(pred, true, k = 1):
    intersection = 2.0 *np.sum(pred * (true==k), axis=(1,2,3))
    dice = intersection / (pred.sum(axis=(1,2,3)) + true.sum(axis=(1,2,3))) 
    return dice

import matplotlib.pyplot as plt
def modelviewer(model):
  plt.figure(figsize=(8,8))
  plt.subplot(2,1,1)
  plt.title('autoencoder')
  plt.plot(model.history['decoder_output_loss'])
  plt.plot(model.history['val_decoder_output_loss'])
  plt.legend(['loss', 'val_loss'])
  plt.subplot(2,1,2)
  plt.title('classifier')
  plt.plot(model.history['classification_output_loss'])
  plt.plot(model.history['val_classification_output_loss'])
  plt.legend(['loss', 'val_loss'])
  return

import tensorflow as tf
from tensorflow.python.keras import backend as K
from tensorflow.keras import models

def heatmap(x,model):
  
  img_tensor =x[np.newaxis,...]
  preds = model.predict(img_tensor)[1]
  argmax = np.argmax(preds)
  conv_layer = model.get_layer("last_conv")
  heatmap_model = models.Model([model.inputs], [conv_layer.output, model.output])

  # Get gradient of the winner class w.r.t. the output of the (last) conv. layer
  with tf.GradientTape() as gtape:
      conv_output, predictions = heatmap_model(img_tensor)
      loss = predictions[1][:, np.argmax(predictions[1])]
      grads = gtape.gradient(loss, conv_output)
      pooled_grads = K.mean(grads, axis=(0, 1, 2))

  heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)
  heatmap = np.maximum(heatmap, 0)
  max_heat = np.max(heatmap)
  if max_heat == 0:
      max_heat = 1e-10
  heatmap /= max_heat

  #print(heatmap.shape)

  # Render heatmap via pyplot
  plt.matshow(heatmap.squeeze())
  plt.show()
    
  x = np.asarray(255*x, np.uint8)
  heatmap = np.asarray(255*heatmap.squeeze(), np.uint8)


  heatmap = cv2.resize(heatmap, (x.shape[1], x.shape[0]))

    
    #superimposed_img = heatmap * hif + x
  plt.imshow(blender(x,heatmap,1,1))
  plt.axis('off')
  if argmax==1:
    plt.title('the mass is malign')
  else:
    plt.title('the mass is benign')

import tensorflow as tf
from tensorflow.python.keras import backend as K
from tensorflow.keras import models

def heatmap_rad(x,feature,model):
  
  img_tensor =x[np.newaxis,...]
  feature_tensor=feature[np.newaxis,...]
  preds = model.predict([img_tensor,feature_tensor])[1]
  argmax = np.argmax(preds)
  conv_layer = model.get_layer("last_conv")
  heatmap_model = models.Model([model.inputs], [conv_layer.output, model.output])

  # Get gradient of the winner class w.r.t. the output of the (last) conv. layer
  with tf.GradientTape() as gtape:
      conv_output, predictions = heatmap_model([img_tensor,feature_tensor])
      loss = predictions[1][:, np.argmax(predictions[1])]
      grads = gtape.gradient(loss, conv_output)
      pooled_grads = K.mean(grads, axis=(0, 1, 2))

  heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)
  heatmap = np.maximum(heatmap, 0)
  max_heat = np.max(heatmap)
  if max_heat == 0:
      max_heat = 1e-10
  heatmap /= max_heat

  #print(heatmap.shape)

  # Render heatmap via pyplot
  plt.matshow(heatmap.squeeze())
  plt.show()
    
  x = np.asarray(255*x, np.uint8)
  heatmap = np.asarray(255*heatmap.squeeze(), np.uint8)


  heatmap = cv2.resize(heatmap, (x.shape[1], x.shape[0]))

    
    #superimposed_img = heatmap * hif + x
  plt.imshow(blender(x,heatmap,1,1))
  plt.axis('off')
  if argmax==1:
    plt.title('the mass is malign')
  else:
    plt.title('the mass is benign')

def plot_roc_curve(fper, tper):  
    plt.plot(fper, tper, color='orange', label='ROC')
    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve with AUC = %.2f'%auc_keras)
    plt.legend()
    plt.show()

from skimage.filters import threshold_multiotsu
def otsu(image,n_items=2):
  thresholds = threshold_multiotsu(image,classes=n_items)
  regions = np.digitize(image, bins=thresholds)
  return regions

"""#Define the models with radiomics feature"""

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension
# %load_ext tensorboard

import tensorflow as tf
import datetime, os

from keras.layers import Conv2D, Conv2DTranspose, Input, Dropout,MaxPooling2D, UpSampling2D, Dense, Flatten
from keras.models import Model, load_model
from keras.layers.experimental.preprocessing import Resizing
from keras.layers.merge import concatenate

def make_model_rad_REGULIZER(shape_tensor=X_train_rad_tr.shape[1:],feature_dim=feature_train_tr.shape[1:]):
    input_tensor = Input(shape=shape_tensor,name="tensor_input")
    input_vector= Input(shape=feature_dim)

    x = Conv2D(32, (5, 5), strides=2, padding='same', activation='relu')(input_tensor)
    x = Dropout(.2,)(x)
    x = MaxPooling2D((2, 2), strides=(2,2),padding='same')(x)
    x = Conv2D(64, (3,3), strides=2,  padding='same', activation='relu')(x)
    x = Dropout(.2,)(x) 
    x = Conv2D(128, (3,3), strides=2, padding='same', activation='relu',name='last_conv')(x)

    flat=Flatten()(x)
    flat=concatenate([flat,input_vector])
    den = Dense(16, activation='relu')(flat)
    #den= Dropout(.1,)(den)
    



    classification_output = Dense(2, activation = 'sigmoid', name="classification_output")(den)
    
    x = Conv2DTranspose(64, (3,3), strides=2,  padding='same', activation='relu')(x)
    x = Dropout(.2,)(x)
    x = UpSampling2D((2, 2))(x)
    x = Conv2DTranspose(32, (3,3), strides=2, padding='same',activation='relu')(x)
    x = Conv2DTranspose(32, (3,3), strides=2, padding='same',activation='relu')(x)
    decoder_out = Conv2D(1, (5,5), padding='valid',activation='sigmoid',name="decoder_output")(x)
    model = Model([input_tensor,input_vector], [decoder_out,classification_output])
    
    return model

def make_model_rad_REGULIZER_V2(shape_tensor=X_train_rad_tr.shape[1:],feature_dim=feature_train_tr.shape[1:]):
    input_tensor = Input(shape=shape_tensor,name="tensor_input")
    input_vector= Input(shape=feature_dim)
    #encoder
    c1 = Conv2D(32, (5, 5), strides=2, padding='same', activation='relu')(input_tensor)
    c1 = Dropout(.2,)(c1)
    m1 = MaxPooling2D((2, 2), strides=(2,2),padding='same')(c1)
    c2 = Conv2D(64, (3,3), strides=2,  padding='same', activation='relu')(m1)
    c2 = Dropout(.2,)(c2) 
    c3 = Conv2D(128, (3,3), strides=2, padding='same', activation='relu',name='last_conv')(c2)
    #classifier
    flat=Flatten()(c3)
    flat=concatenate([flat,input_vector])
    den = Dense(16, activation='relu')(flat)  
    classification_output = Dense(2, activation = 'sigmoid', name="classification_output")(den)
    #decoder
    t1 = Conv2DTranspose(64, (3,3), strides=2,  padding='same', activation='relu')(c3)
    t1 = Dropout(.2,)(t1)
    t1=concatenate([t1,c2])
    u1 = UpSampling2D((2, 2))(t1)
    t2 = Conv2DTranspose(32, (3,3), strides=2, padding='same',activation='relu')(u1)
    t3 = Conv2DTranspose(32, (3,3), strides=2, padding='same',activation='relu')(t2)
    decoder_out = Conv2D(1, (5,5), padding='valid',activation='sigmoid',name="decoder_output")(t3)
    model = Model([input_tensor,input_vector], [decoder_out,classification_output])
    
    return model

feature_train_tr.shape[1:]

def make_model_rad(shape_tensor=X_train_rad_tr.shape[1:],feature_dim=feature_train_tr.shape[1:]):
    input_tensor = Input(shape=shape_tensor)
    input_vector= Input(shape=feature_dim)
    
    x = Conv2D(32, (5, 5), strides=2, padding='same', activation='relu')(input_tensor)
    #x = Dropout(.2)(x)
    x = Conv2D(64, (3,3), strides=2,  padding='same', activation='relu')(x)
    #x = Dropout(.2)(x)
    x = Conv2D(128, (3,3), strides=2, padding='same', activation='relu',name='last_conv')(x)

    flat=Flatten()(x)
    flat=concatenate([flat,input_vector])
    den = Dense(16, activation='relu')(flat)
    #den = Dropout(.2)(den)

    classification_output = Dense(2, activation = 'sigmoid', name="classification_output")(flat)

    x = Conv2DTranspose(64, (3,3), strides=2,  padding='same', activation='relu')(x)
    x = Conv2DTranspose(32, (3,3), strides=2, padding='same',activation='relu')(x)
    x = Conv2DTranspose(32, (3,3), strides=2, padding='same',activation='relu')(x)
    decoder_out = Conv2D(1, (5,5), padding='valid',activation='sigmoid',name="decoder_output")(x)
    model = Model([input_tensor,input_vector], [decoder_out,classification_output])
    
    return model

from keras.constraints import unit_norm,min_max_norm,max_norm
from tensorflow.keras import regularizers

 
def make_model_rad_UNET(shape_tensor=X_train_rad_tr.shape[1:],feature_dim=feature_train_tr.shape[1:]):
    input_tensor = Input(shape=shape_tensor)
    input_vector= Input(shape=feature_dim)

    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(input_tensor)
    c1 = Dropout(0.2)(c1)
    c1 = Conv2D(16, (3, 3),activation='relu', kernel_initializer='he_normal',
                            padding='same')(c1)
    p1 =MaxPooling2D((2, 2))(c1)
    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(p1)
    c2 = Dropout(0.1)(c2)
    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c2)
    p2 = MaxPooling2D((2, 2))(c2)
    p2 = Resizing(32,32,interpolation='nearest')(p2)
    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(p2)

    
    c3 = Dropout(0.2)(c3)
    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same', name="last_conv")(c3)
    p3 = MaxPooling2D((2, 2))(c3)
    p3 = Resizing(16,16,interpolation='nearest')(p3)
    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(p3)
    c4 = Dropout(0.2)(c4)
    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c4)

    p4 = MaxPooling2D((2, 2))(c4)

    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(p4)
                            
    c5 = Dropout(0.2)(c5)
    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c5)
#fc layers

    flat=Flatten()(c3)   
    flat=concatenate([flat,input_vector]) 
    den = Dense(16, activation='relu', activity_regularizer=regularizers.l2(1e-4))(flat)
    #den= Dropout(.3,)(den)
    #den = Dense(4, activation='relu', activity_regularizer=regularizers.l2(1e-4))(den)
    #den = Dropout(.5,)(den)
    #den = Dense(4, activation='relu', activity_regularizer=regularizers.l2(1e-4))(den)
    #den = Dropout(.5,)(den)
    #den = Dense(64, activation='relu', activity_regularizer=regularizers.l2(1e-4))(den)
    #den = Dropout(.3,)(den)
    #den= Dense(4, activation='relu', activity_regularizer=regularizers.l2(1e-4))(den)
    #den = Dropout(.5,)(den)

    classification_output = Dense(2, activation = 'softmax', name="classification_output")(flat)

    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)
    
    #c4 = Resizing(14,14,interpolation='nearest')(c4)
    u6 = concatenate([u6, c4])
    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(u6)
    c6 = Dropout(0.2)(c6)
    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c6)

    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)
    #c3= Resizing(28,28,interpolation='nearest')(c3)

    u7 = concatenate([u7, c3])
    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(u7)
    c7 = Dropout(0.2)(c7)
    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c7)

    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)
    u8 = Resizing(62,62,interpolation='nearest')(c2)

    u8 = concatenate([u8, c2])
    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(u8)
    c8 = Dropout(0.2)(c8)
    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c8)

    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)
    #c1= Resizing(112,112,interpolation='nearest')(c1)

    u9 = concatenate([u9, c1], axis=3)
    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(u9)
    c9 = Dropout(0.2)(c9)
    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c9)


    decoder_out = Conv2D(1, (1, 1), activation='sigmoid',name="decoder_output")(c9)

    model = Model([input_tensor,input_vector], [decoder_out,classification_output])
    return model

import tensorflow as tf
model_rad = make_model_rad_REGULIZER() 
model_rad.summary()

logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)

checkpoint_filepath = 'weights.{epoch:02d}-{val_loss:.2f}.h5'
model_checkpoint_callback = keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_filepath,
    monitor='val_classification_output_auc_4',
    mode='max',
    save_best_only=True)

model_rad.compile(optimizer='adam', loss={'decoder_output':'binary_crossentropy','classification_output':'categorical_crossentropy'},
                  metrics={'decoder_output':'MAE','classification_output':tf.keras.metrics.AUC()})

epoch_number= 50

history_rad = model_rad.fit(mass_gen_rad, steps_per_epoch=len(mass_gen_rad), epochs=epoch_number, 
                        validation_data=([X_train_rad_val,feature_train_val] ,[Y_train_rad_val,class_train_rad_val]),
                        callbacks=[tensorboard_callback])

"""View on tensorboard"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs

"""View the results"""

modelviewer(history_rad)

"""Save the model"""

#model_rad.save('/content/drive/My Drive/model_radiomics_best_sofar_regulizer')

"""We can optionally load the model"""

#from tensorflow import keras
#model_rad = keras.models.load_model('/content/drive/My Drive/model_radiomics_best_sofar_regulizer')
#model.summary()

model_rad = keras.models.load_model('/content/drive/MyDrive/weights.35-0.47.h5')

"""We visualize the output on images of the train set ...ADD THE FEATURE VECTOR!!!"""

idx=67
xtrain = X_train_rad[idx][np.newaxis,...]
ytrain = Y_train_rad[idx][np.newaxis,...]
xtrain.shape

feature_train[idx][np.newaxis,...].shape

np.argmax(model_rad.predict([xtrain,feature_train[idx][np.newaxis,...]])[1]),class_train[idx]

plt.figure(figsize=(14,4))
plt.subplot(1,3,1)
plt.imshow(xtrain.squeeze())
plt.subplot(1,3,2)
plt.imshow(ytrain.squeeze())
plt.subplot(1,3,3)
plt.imshow(otsu(model_rad.predict([xtrain,feature_train[idx][np.newaxis,...]])[0].squeeze()))

"""and on images of the test set (never seen by the CAE) """

idx=16
xtest = X_test[idx][np.newaxis,...]
ytest = Y_test[idx][np.newaxis,...]
xtest.shape

plt.figure(figsize=(14,4))
plt.subplot(1,3,1)
plt.imshow(xtest.squeeze())
plt.subplot(1,3,2)
plt.imshow(ytest.squeeze())
plt.subplot(1,3,3)
plt.imshow(otsu(model_rad.predict([xtest,feature_test[idx][np.newaxis,...]])[0].squeeze()))

"""We compute the Dice index for the train examples:"""

idx=13

xtrain = X_train[idx][np.newaxis,...]
ytrain = Y_train[idx][np.newaxis,...]
feats=feature_train[idx][np.newaxis,...]
print(Y_train[idx].shape, ytrain.shape)

ypred = otsu(model_rad.predict([xtrain,feats])[0].squeeze())
ytrue = Y_train[idx].squeeze()
print(ypred.shape, ytrue.shape)

dice_value_rad = dice(ypred, ytrue)
print(dice_value_rad)

"""We want to compute the Dice index for all images in the np.arrays of the train and test sets"""

dice_vectorized(ytrain,otsu(model_rad.predict([xtrain,feats])[0]))

"""The average Dice on the train set is:"""

dice_vectorized(Y_train,otsu(model_rad.predict([X_train,feature_train])[0])).mean()

dice_vectorized(Y_test,otsu(model_rad.predict([X_test,feature_test])[0])).mean()

heatmap_rad(X_test[18],feature_test[18],model_rad) 
plt.imshow((X_test[18].squeeze())

i=18
print(np.argmax(model_rad.predict([X_test[i][np.newaxis,...],feature_test[i][np.newaxis,...]])[1]),class_train[i])

"""Now the roc curve"""

from sklearn.metrics import roc_curve
y_pred = model_rad.predict([X_test_rad,feature_test])[1]
fpr_keras, tpr_keras, thresholds_keras = roc_curve(class_test, [item[0] for _,item in enumerate(y_pred)],pos_label=0)

from sklearn.metrics import auc
auc_keras = auc(fpr_keras, tpr_keras)

plot_roc_curve(fpr_keras, tpr_keras)

"""otsu's binarization"""

X_test[16].shape

segmented=otsu(model_rad.predict([X_test[16][np.newaxis,...],feature_test[16][np.newaxis,...]])[0].squeeze(),2)
plt.figure()
plt.imshow(segmented)

"""#Define the models with radiomics and bigger dataset"""

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension
# %load_ext tensorboard

import tensorflow as tf
import datetime, os

from keras.layers import Conv2D, Conv2DTranspose, Input, Dropout,MaxPooling2D, UpSampling2D, Dense, Flatten
from keras.models import Model, load_model
from keras.layers.experimental.preprocessing import Resizing
from keras.layers.merge import concatenate

def make_model_rad_BIG_REGULIZER(shape_tensor=(4096,3072,1),feature_dim=feature_train_big_tr.shape[1:]):
    input_tensor = Input(shape=shape_tensor,name="tensor_input")
    input_vector= Input(shape=feature_dim)

    x = Conv2D(32, (5, 5), strides=2, padding='same', activation='relu')(input_tensor)
    x = Dropout(.2,)(x)
    x = MaxPooling2D((2, 2), strides=(2,2),padding='same')(x)
    x = Conv2D(64, (3,3), strides=2,  padding='same', activation='relu')(x)
    x = Dropout(.2,)(x) 
    x = Conv2D(128, (3,3), strides=2, padding='same', activation='relu',name='last_conv')(x)

    flat=Flatten()(x)
    flat=concatenate([flat,input_vector])
    den = Dense(16, activation='relu')(flat)
    #den= Dropout(.1,)(den)
    



    classification_output = Dense(2, activation = 'sigmoid', name="classification_output")(den)
    
    x = Conv2DTranspose(64, (3,3), strides=2,  padding='same', activation='relu')(x)
    x = Dropout(.2,)(x)
    x = UpSampling2D((2, 2))(x)
    x = Conv2DTranspose(32, (3,3), strides=2, padding='same',activation='relu')(x)
    x = Conv2DTranspose(32, (3,3), strides=2, padding='same',activation='relu')(x)
    decoder_out = Conv2D(1, (5,5), padding='valid',activation='sigmoid',name="decoder_output")(x)
    model = Model([input_tensor,input_vector], [decoder_out,classification_output])
    
    return model

def make_model_rad_BIG_REGULIZER_V2(shape_tensor=(4096,3072,1),feature_dim=feature_train_big_tr.shape[1:]):
    input_tensor = Input(shape=shape_tensor,name="tensor_input")
    input_vector= Input(shape=feature_dim)
    #encoder
    c1 = Conv2D(32, (5, 5), strides=2, padding='same', activation='relu')(input_tensor)
    c1 = Dropout(.2,)(c1)
    m1 = MaxPooling2D((2, 2), strides=(2,2),padding='same')(c1)
    c2 = Conv2D(64, (3,3), strides=2,  padding='same', activation='relu')(m1)
    c2 = Dropout(.2,)(c2) 
    c3 = Conv2D(128, (3,3), strides=2, padding='same', activation='relu',name='last_conv')(c2)
    #classifier
    flat=Flatten()(c3)
    flat=concatenate([flat,input_vector])
    den = Dense(16, activation='relu')(flat)  
    classification_output = Dense(2, activation = 'sigmoid', name="classification_output")(den)
    #decoder
    t1 = Conv2DTranspose(64, (3,3), strides=2,  padding='same', activation='relu')(c3)
    t1 = Dropout(.2,)(t1)
    t1=concatenate([t1,c2])
    u1 = UpSampling2D((2, 2))(t1)
    t2 = Conv2DTranspose(32, (3,3), strides=2, padding='same',activation='relu')(u1)
    t3 = Conv2DTranspose(32, (3,3), strides=2, padding='same',activation='relu')(t2)
    decoder_out = Conv2D(1, (5,5), padding='valid',activation='sigmoid',name="decoder_output")(t3)
    model = Model([input_tensor,input_vector], [decoder_out,classification_output])
    
    return model

feature_train_big_tr.shape[1:]

def make_model_rad_BIG(shape_tensor=(2048, 1536, 1),feature_dim=feature_train_big_tr.shape[1:]):
    input_tensor = Input(shape=shape_tensor)
    input_vector= Input(shape=feature_dim)
    
    x = Conv2D(32, (5, 5), strides=2, padding='same', activation='relu')(input_tensor)
    #x = Dropout(.2)(x)
    x = Conv2D(64, (3,3), strides=2,  padding='same', activation='relu')(x)
    #x = Dropout(.2)(x)
    x = Conv2D(128, (3,3), strides=2, padding='same', activation='relu',name='last_conv')(x)

    flat=Flatten()(x)
    flat=concatenate([flat,input_vector])
    den = Dense(16, activation='relu')(flat)
    #den = Dropout(.2)(den)

    classification_output = Dense(2, activation = 'sigmoid', name="classification_output")(flat)

    x = Conv2DTranspose(64, (3,3), strides=2,  padding='same', activation='relu')(x)
    x = Conv2DTranspose(32, (3,3), strides=2, padding='same',activation='relu')(x)
    x = Conv2DTranspose(32, (3,3), strides=2, padding='same',activation='relu')(x)
    decoder_out = Conv2D(1,(1,1) , padding='valid',activation='sigmoid',name="decoder_output")(x)
    model = Model([input_tensor,input_vector], [decoder_out,classification_output])
    
    return model

from keras.constraints import unit_norm,min_max_norm,max_norm
from tensorflow.keras import regularizers

 
def make_model_rad_BIG_UNET(shape_tensor=(1024, 768, 1),feature_dim=feature_train_big_tr.shape[1:]):
    input_tensor = Input(shape=shape_tensor)
    input_vector= Input(shape=feature_dim)

    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(input_tensor)
    c1 = Dropout(0.2)(c1)
    c1 = Conv2D(16, (3, 3),activation='relu', kernel_initializer='he_normal',
                            padding='same')(c1)
    p1 =MaxPooling2D((2, 2))(c1)
    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(p1)
    c2 = Dropout(0.1)(c2)
    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c2)
    p2 = MaxPooling2D((2, 2))(c2)
    #p2 = Resizing(32,32,interpolation='nearest')(p2)
    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(p2)

    
    c3 = Dropout(0.2)(c3)
    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same', name="last_conv")(c3)
    p3 = MaxPooling2D((2, 2))(c3)
    #p3 = Resizing(16,16,interpolation='nearest')(p3)
    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(p3)
    c4 = Dropout(0.2)(c4)
    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c4)

    p4 = MaxPooling2D((2, 2))(c4)

    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(p4)
                            
    c5 = Dropout(0.2)(c5)
    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c5)
#fc layers

    flat=Flatten()(c3)   
    flat=concatenate([flat,input_vector]) 
    den = Dense(16, activation='relu', activity_regularizer=regularizers.l2(1e-4))(flat)
    #den= Dropout(.3,)(den)
    #den = Dense(4, activation='relu', activity_regularizer=regularizers.l2(1e-4))(den)
    #den = Dropout(.5,)(den)
    #den = Dense(4, activation='relu', activity_regularizer=regularizers.l2(1e-4))(den)
    #den = Dropout(.5,)(den)
    #den = Dense(64, activation='relu', activity_regularizer=regularizers.l2(1e-4))(den)
    #den = Dropout(.3,)(den)
    #den= Dense(4, activation='relu', activity_regularizer=regularizers.l2(1e-4))(den)
    #den = Dropout(.5,)(den)

    classification_output = Dense(2, activation = 'softmax', name="classification_output")(flat)

    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)
    
    #c4 = Resizing(14,14,interpolation='nearest')(c4)
    u6 = concatenate([u6, c4])
    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(u6)
    c6 = Dropout(0.2)(c6)
    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c6)

    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)
    #c3= Resizing(28,28,interpolation='nearest')(c3)

    u7 = concatenate([u7, c3])
    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(u7)
    c7 = Dropout(0.2)(c7)
    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c7)

    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)
    #u8 = Resizing(62,62,interpolation='nearest')(c2)

    u8 = concatenate([u8, c2])
    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(u8)
    c8 = Dropout(0.2)(c8)
    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c8)

    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)
    #c1= Resizing(112,112,interpolation='nearest')(c1)

    u9 = concatenate([u9, c1], axis=3)
    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(u9)
    c9 = Dropout(0.2)(c9)
    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c9)


    decoder_out = Conv2D(1, (1, 1), activation='sigmoid',name="decoder_output")(c9)

    model = Model([input_tensor,input_vector], [decoder_out,classification_output])
    return model

import tensorflow as tf
model_rad = make_model_rad_BIG_UNET() 
model_rad.summary()

logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)

checkpoint_filepath = 'big_weights.{epoch:02d}-{val_loss:.2f}.h5'
model_checkpoint_callback = keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_filepath,
    monitor='val_classification_output_auc_2',
    mode='max',
    save_best_only=True)

model_rad.compile(optimizer='adam', loss={'decoder_output':'binary_crossentropy','classification_output':'categorical_crossentropy'},
                  metrics={'decoder_output':'MAE','classification_output':tf.keras.metrics.AUC()})

epoch_number= 10

history_rad = model_rad.fit(mass_gen_rad_big, steps_per_epoch=10, epochs=epoch_number, 
                        validation_data=Validation_data,
                        callbacks=[tensorboard_callback,model_checkpoint_callback])

"""View on tensorboard"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs

"""View the results"""

modelviewer(history_rad)

"""Save the model"""

#model_rad.save('/content/drive/My Drive/model_radiomics_best_sofar_regulizer')

"""We can optionally load the model"""

#from tensorflow import keras
#model_rad = keras.models.load_model('/content/drive/My Drive/model_radiomics_best_sofar_regulizer')
#model.summary()

model_rad = keras.models.load_model('/content/drive/MyDrive/weights.35-0.47.h5')

"""We visualize the output on images of the train set ...ADD THE FEATURE VECTOR!!!"""

idx=67
xtrain = X_train_rad[idx][np.newaxis,...]
ytrain = Y_train_rad[idx][np.newaxis,...]
xtrain.shape

feature_train[idx][np.newaxis,...].shape

np.argmax(model_rad.predict([xtrain,feature_train[idx][np.newaxis,...]])[1]),class_train[idx]

plt.figure(figsize=(14,4))
plt.subplot(1,3,1)
plt.imshow(xtrain.squeeze())
plt.subplot(1,3,2)
plt.imshow(ytrain.squeeze())
plt.subplot(1,3,3)
plt.imshow(otsu(model_rad.predict([xtrain,feature_train[idx][np.newaxis,...]])[0].squeeze()))

"""and on images of the test set (never seen by the CAE) """

idx=16
xtest = X_test[idx][np.newaxis,...]
ytest = Y_test[idx][np.newaxis,...]
xtest.shape

plt.figure(figsize=(14,4))
plt.subplot(1,3,1)
plt.imshow(xtest.squeeze())
plt.subplot(1,3,2)
plt.imshow(ytest.squeeze())
plt.subplot(1,3,3)
plt.imshow(otsu(model_rad.predict([xtest,feature_test[idx][np.newaxis,...]])[0].squeeze()))

"""We compute the Dice index for the train examples:"""

idx=13

xtrain = X_train[idx][np.newaxis,...]
ytrain = Y_train[idx][np.newaxis,...]
feats=feature_train[idx][np.newaxis,...]
print(Y_train[idx].shape, ytrain.shape)

ypred = otsu(model_rad.predict([xtrain,feats])[0].squeeze())
ytrue = Y_train[idx].squeeze()
print(ypred.shape, ytrue.shape)

dice_value_rad = dice(ypred, ytrue)
print(dice_value_rad)

"""We want to compute the Dice index for all images in the np.arrays of the train and test sets"""

dice_vectorized(ytrain,otsu(model_rad.predict([xtrain,feats])[0]))

"""The average Dice on the train set is:"""

dice_vectorized(Y_train,otsu(model_rad.predict([X_train,feature_train])[0])).mean()

dice_vectorized(Y_test,otsu(model_rad.predict([X_test,feature_test])[0])).mean()

heatmap_rad(X_test[18],feature_test[18],model_rad) 
plt.imshow((X_test[18].squeeze())

i=18
print(np.argmax(model_rad.predict([X_test[i][np.newaxis,...],feature_test[i][np.newaxis,...]])[1]),class_train[i])

"""Now the roc curve"""

from sklearn.metrics import roc_curve
y_pred = model_rad.predict([X_test_rad,feature_test])[1]
fpr_keras, tpr_keras, thresholds_keras = roc_curve(class_test, [item[0] for _,item in enumerate(y_pred)],pos_label=0)

from sklearn.metrics import auc
auc_keras = auc(fpr_keras, tpr_keras)

plot_roc_curve(fpr_keras, tpr_keras)

"""otsu's binarization"""

X_test[16].shape

segmented=otsu(model_rad.predict([X_test[16][np.newaxis,...],feature_test[16][np.newaxis,...]])[0].squeeze(),2)
plt.figure()
plt.imshow(segmented)

"""#Now we define the models"""

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension
# %load_ext tensorboard

import tensorflow as tf
import datetime, os

from keras.layers import Conv2D, Conv2DTranspose, Input, Dropout,MaxPooling2D, UpSampling2D, Dense, Flatten
from keras.models import Model, load_model
from keras.layers.experimental.preprocessing import Resizing
from keras.layers.merge import concatenate

"""Model by Liu et al, Deep Convolutional Auto-Encoder and 3D Deformable Approach for Tissue Segmentation in Magnetic Resonance Imaging, Proc. Intl. Soc. Mag. Reson. Med. 25, 2017"""

def make_model(shape=(124,124,1)):
    input_tensor = Input(shape=shape)
    
    x = Conv2D(32, (5, 5), strides=2, padding='same', activation='relu')(input_tensor)
    x = Conv2D(64, (3,3), strides=2,  padding='same', activation='relu')(x)
    x = Conv2D(128, (3,3), strides=2, padding='same', activation='relu',name='last_conv')(x)

    flat=Flatten()(x)
    #den = Dense(128, activation='relu')(flat)
    classification_output = Dense(2, activation = 'sigmoid', name="classification_output")(flat)

    x = Conv2DTranspose(64, (3,3), strides=2,  padding='same', activation='relu')(x)
    x = Conv2DTranspose(32, (3,3), strides=2, padding='same',activation='relu')(x)
    x = Conv2DTranspose(32, (3,3), strides=2, padding='same',activation='relu')(x)
    decoder_out = Conv2D(1, (5,5), padding='valid',activation='sigmoid',name="decoder_output")(x)
    model = Model(input_tensor, [decoder_out,classification_output])
    
    return model

"""Model 2 is the same but with added regularization (dropout layers) and maxpooling


"""

def make_modelREGULIZER(shape=(124,124,1)):
    input_tensor = Input(shape=shape,name="model_input")
    
    x = Conv2D(32, (5, 5), strides=2, padding='same', activation='relu')(input_tensor)
    x = Dropout(.2,)(x)
    x = MaxPooling2D((2, 2), strides=(2,2),padding='same')(x)
    x = Conv2D(64, (3,3), strides=2,  padding='same', activation='relu')(x)
    x = Dropout(.2,)(x) 
    x = Conv2D(128, (3,3), strides=2, padding='same', activation='relu',name='last_conv')(x)

    flat=Flatten()(x)
    den = Dense(32, activation='relu')(flat)
    den= Dropout(.1,)(den)
    den = Dense(16, activation='relu')(den)
    den = Dropout(.3,)(den)
    den = Dense(8, activation='relu')(den)
    den = Dropout(.3,)(den)
    den = Dense(4, activation='relu')(den)



    classification_output = Dense(2, activation = 'sigmoid', name="classification_output")(den)
    
    x = Conv2DTranspose(64, (3,3), strides=2,  padding='same', activation='relu')(x)
    x = Dropout(.2,)(x)
    x = UpSampling2D((2, 2))(x)
    x = Conv2DTranspose(32, (3,3), strides=2, padding='same',activation='relu')(x)
    x = Conv2DTranspose(32, (3,3), strides=2, padding='same',activation='relu')(x)
    decoder_out = Conv2D(1, (5,5), padding='valid',activation='sigmoid',name="decoder_output")(x)
    model = Model(input_tensor, [decoder_out,classification_output])
    
    return model

"""Model 3 is a deeper CAE with a resizing layer"""

def make_modelDEEP(shape=(124,124,1)):
    input_tensor = Input(shape=shape)
    
    #encoder
    x = Conv2D(32, (3, 3), strides=1, padding='same', activation='relu')(input_tensor)

    x = Dropout(.2,)(x)

    x = MaxPooling2D((2, 2), strides=2,padding='same')(x)

    x = Resizing(60,60,interpolation='nearest')(x)

    x = Conv2D(64, (3,3), strides=1,  padding='same', activation='relu')(x)

    x = Dropout(.2,)(x) 

    x = MaxPooling2D((2, 2), strides=2,padding='same')(x)

    x = Conv2D(128, (3,3), strides=3, padding='same', activation='relu')(x)

    x = Dropout(.2,)(x)

    x = Conv2D(256, (2,2), strides=2, padding='same',activation='relu',name='last_conv')(x)

    #fc layers

    flat=Flatten()(x)
    den = Dense(32, activation='relu')(flat)
    den= Dropout(.1,)(den)
    den = Dense(16, activation='relu')(den)
    den = Dropout(.3,)(den)
    den = Dense(8, activation='relu')(den)
    den = Dropout(.3,)(den)
    den = Dense(4, activation='relu')(den)



    classification_output = Dense(2, activation = 'sigmoid', name="classification_output")(den)

    #decoder

    x = Conv2DTranspose(256, (2,2), strides=2, padding='same', activation='relu')(x)

    x = Dropout(.2,)(x)

    x = Conv2DTranspose(128, (2,2), strides=2, padding='same', activation='relu')(x)

    x = Dropout(.2,)(x)

    x = Conv2DTranspose(128, (2,2), strides=2, padding='same', activation='relu')(x)

    x = Dropout(.2,)(x)

    x = Conv2DTranspose(64, (2,2), strides=2, padding='same', activation='relu')(x)

    x = Dropout(.2,)(x)


    x = Conv2DTranspose(32, (2,2), strides=2, padding='same', activation='relu')(x)

    x = Resizing(124,124,interpolation='nearest')(x)

    decoder_out = Conv2D(1,(3,3),padding='same',activation='sigmoid',name="decoder_output")(x)

    
    #out= Resizing(124,124,interpolation='nearest')(out)
    
    model = Model(input_tensor, [decoder_out,classification_output])  


    return model

"""This model is the Unet from Ronneberger e al, U-Net: Convolutional Networks for Biomedical
Image Segmentation. I added a resizing layer to adapt it for our image size

"""

from keras.constraints import unit_norm,min_max_norm,max_norm
from tensorflow.keras import regularizers

 
def make_modelUNET(shape=(124,124,1)):
    input_tensor = Input(shape=shape)

    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(input_tensor)
    c1 = Dropout(0.2)(c1)
    c1 = Conv2D(16, (3, 3),activation='relu', kernel_initializer='he_normal',
                            padding='same')(c1)
    p1 =MaxPooling2D((2, 2))(c1)
    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(p1)
    c2 = Dropout(0.1)(c2)
    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c2)
    p2 = MaxPooling2D((2, 2))(c2)
    p2 = Resizing(32,32,interpolation='nearest')(p2)
    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(p2)

    
    c3 = Dropout(0.2)(c3)
    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c3)
    p3 = MaxPooling2D((2, 2))(c3)
    p3 = Resizing(16,16,interpolation='nearest')(p3)
    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(p3)
    c4 = Dropout(0.2)(c4)
    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c4)

    p4 = MaxPooling2D((2, 2))(c4)

    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(p4)
                            
    c5 = Dropout(0.2)(c5)
    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same', name="last_conv")(c5)
#fc layers

    flat=Flatten()(c5)    
    den = Dense(32, activation='relu', activity_regularizer=regularizers.l2(1e-4))(flat)
    den= Dropout(.3,)(den)
    den = Dense(16, activation='relu', activity_regularizer=regularizers.l2(1e-4))(den)
    den = Dropout(.3,)(den)
    den = Dense(8, activation='relu', activity_regularizer=regularizers.l2(1e-4))(den)
    #den = Dropout(.3,)(den)
    den = Dense(4, activation='relu', activity_regularizer=regularizers.l2(1e-4))(den)
    #den = Dropout(.3,)(den)
    #den= Dense(2, activation='relu', kernel_constraint=unit_norm())(den)
    classification_output = Dense(2, activation = 'sigmoid', name="classification_output")(den)

    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)
    
    #c4 = Resizing(14,14,interpolation='nearest')(c4)
    u6 = concatenate([u6, c4])
    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(u6)
    c6 = Dropout(0.2)(c6)
    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c6)

    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)
    #c3= Resizing(28,28,interpolation='nearest')(c3)

    u7 = concatenate([u7, c3])
    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(u7)
    c7 = Dropout(0.2)(c7)
    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c7)

    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)
    u8 = Resizing(62,62,interpolation='nearest')(c2)

    u8 = concatenate([u8, c2])
    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(u8)
    c8 = Dropout(0.2)(c8)
    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c8)

    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)
    #c1= Resizing(112,112,interpolation='nearest')(c1)

    u9 = concatenate([u9, c1], axis=3)
    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(u9)
    c9 = Dropout(0.2)(c9)
    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c9)


    decoder_out = Conv2D(1, (1, 1), activation='sigmoid',name="decoder_output")(c9)

    model = Model(input_tensor, [decoder_out,classification_output])  
    return model

from keras.constraints import unit_norm,min_max_norm,max_norm
from tensorflow.keras import regularizers

 
def make_modelUNETBIG(shape=(4800, 2656,1)):
    input_tensor = Input(shape=shape)

    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(input_tensor)
    c1 = Dropout(0.2)(c1)
    c1 = Conv2D(16, (3, 3),activation='relu', kernel_initializer='he_normal',
                            padding='same')(c1)
    p1 =MaxPooling2D((2, 2))(c1)
    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(p1)
    c2 = Dropout(0.1)(c2)
    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c2)
    p2 = MaxPooling2D((2, 2))(c2)
    #p2 = Resizing(32,32,interpolation='nearest')(p2)
    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(p2)

    
    c3 = Dropout(0.2)(c3)
    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c3)
    p3 = MaxPooling2D((2, 2))(c3)
    #p3 = Resizing(16,16,interpolation='nearest')(p3)
    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(p3)
    c4 = Dropout(0.2)(c4)
    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c4)

    p4 = MaxPooling2D((2, 2))(c4)

    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(p4)
                            
    c5 = Dropout(0.2)(c5)
    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same', name="last_conv")(c5)
#fc layers

    flat=Flatten()(c5)    
    den = Dense(32, activation='relu', activity_regularizer=regularizers.l2(1e-4))(flat)
    den= Dropout(.3,)(den)
    den = Dense(16, activation='relu', activity_regularizer=regularizers.l2(1e-4))(den)
    den = Dropout(.3,)(den)
    den = Dense(8, activation='relu', activity_regularizer=regularizers.l2(1e-4))(den)
    #den = Dropout(.3,)(den)
    den = Dense(4, activation='relu', activity_regularizer=regularizers.l2(1e-4))(den)
    #den = Dropout(.3,)(den)
    #den= Dense(2, activation='relu', kernel_constraint=unit_norm())(den)
    classification_output = Dense(2, activation = 'sigmoid', name="classification_output")(den)

    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)
    
    #c4 = Resizing(14,14,interpolation='nearest')(c4)
    u6 = concatenate([u6, c4])
    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(u6)
    c6 = Dropout(0.2)(c6)
    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c6)

    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)
    #c3= Resizing(28,28,interpolation='nearest')(c3)

    u7 = concatenate([u7, c3])
    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(u7)
    c7 = Dropout(0.2)(c7)
    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c7)

    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)
    #u8 = Resizing(62,62,interpolation='nearest')(c2)

    u8 = concatenate([u8, c2])
    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(u8)
    c8 = Dropout(0.2)(c8)
    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c8)

    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)
    #c1= Resizing(112,112,interpolation='nearest')(c1)

    u9 = concatenate([u9, c1], axis=3)
    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(u9)
    c9 = Dropout(0.2)(c9)
    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c9)


    decoder_out = Conv2D(1, (1, 1), activation='sigmoid',name="decoder_output")(c9)

    model = Model(input_tensor, [decoder_out,classification_output])  
    return model



"""#Now we start the training

#Now we use keras tuner to tune the classifier
"""

!pip install keras-tuner

from kerastuner.tuners import RandomSearch, BayesianOptimization
from kerastuner.engine.hyperparameters import HyperParameters

import time
LOG_DIR = f"{int(time.time())}"

from keras.constraints import unit_norm,min_max_norm,max_norm
from tensorflow.keras import regularizers

 
def build_model_rad_UNET(hp,shape=(124,124,1),feature_dim=(3,)):
    input_tensor = Input(shape=shape)
    input_vector= Input(shape=feature_dim)

    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(input_tensor)
    c1 = Dropout(0.2)(c1)
    c1 = Conv2D(16, (3, 3),activation='relu', kernel_initializer='he_normal',
                            padding='same')(c1)
    p1 =MaxPooling2D((2, 2))(c1)
    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(p1)
    c2 = Dropout(0.1)(c2)
    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c2)
    p2 = MaxPooling2D((2, 2))(c2)
    p2 = Resizing(32,32,interpolation='nearest')(p2)
    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(p2)

    
    c3 = Dropout(0.2)(c3)
    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c3)
    p3 = MaxPooling2D((2, 2))(c3)
    p3 = Resizing(16,16,interpolation='nearest')(p3)
    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(p3)
    c4 = Dropout(0.2)(c4)
    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c4)

    p4 = MaxPooling2D((2, 2))(c4)

    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(p4)
                            
    c5 = Dropout(0.2)(c5)
    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same', name="last_conv")(c5)
#fc layers

    flat=Flatten()(c5) 
    flat=concatenate([flat,input_vector])   
    den = Dense(hp.Int(f'dense_base_unit',
                                min_value=32,
                                max_value=64,
                                step=4), activation='relu', activity_regularizer=regularizers.l2(1e-4))(flat)
                                
    for i in range(hp.Int('n_layers', 1, 4)):  # adding variation of layers.
      
      
      den = Dense(hp.Int(f'conv_{i}_units',
                                min_value=4,
                                max_value=64,
                                step=4), activation='relu', activity_regularizer=regularizers.l2(1e-4))(den)
      den= Dropout(hp.Float(f'drop_{i}_rate',
                                min_value=0,
                                max_value=.5,
                                step=.1,))(den)
    
    classification_output = Dense(2, activation = 'sigmoid', name="classification_output")(den)

    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)
    
    #c4 = Resizing(14,14,interpolation='nearest')(c4)
    u6 = concatenate([u6, c4])
    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(u6)
    c6 = Dropout(0.2)(c6)
    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c6)

    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)
    #c3= Resizing(28,28,interpolation='nearest')(c3)

    u7 = concatenate([u7, c3])
    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(u7)
    c7 = Dropout(0.2)(c7)
    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c7)

    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)
    u8 = Resizing(62,62,interpolation='nearest')(c2)

    u8 = concatenate([u8, c2])
    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(u8)
    c8 = Dropout(0.2)(c8)
    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c8)

    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)
    #c1= Resizing(112,112,interpolation='nearest')(c1)

    u9 = concatenate([u9, c1], axis=3)
    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(u9)
    c9 = Dropout(0.2)(c9)
    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal',
                            padding='same')(c9)


    decoder_out = Conv2D(1, (1, 1), activation='sigmoid',name="decoder_output")(c9)

    model = Model([input_tensor,input_vector], [decoder_out,classification_output])
    model.compile(optimizer='adam', loss={'decoder_output':'binary_crossentropy','classification_output':'categorical_crossentropy'},
                  metrics={'decoder_output':'MAE','classification_output':tf.keras.metrics.AUC()})
    return model

tuner = BayesianOptimization(
    build_model_rad_UNET,
    objective='val_loss',
    max_trials=10,  # how many model variations to test?
    executions_per_trial=1,  # how many trials per variation? (same model could perform differently)
    directory=LOG_DIR)

tuner.search(mass_gen_rad,
             verbose=2, # just slapping this here bc jupyter notebook. The console out was getting messy.
             epochs=250,
             batch_size=len(mass_gen_rad),
             #callbacks=[tensorboard],  # if you have callbacks like tensorboard, they go here.
             validation_data=([X_train_rad_val,feature_train_val], [Y_train_rad_val,class_train_rad_val]))

tuner.get_best_hyperparameters()[0].values

newmod=build_modelUNET(tuner.get_best_hyperparameters()[0])
#newmod.summary()

tuner.get_best_models()[0].summary()

logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)

newmod.compile(optimizer='adam', loss={'decoder_output':'binary_crossentropy','classification_output':'binary_crossentropy'}, metrics={'decoder_output':'MAE','classification_output':tf.keras.metrics.AUC()})

history_tuned = newmod.fit(mass_gen, steps_per_epoch=len(mass_gen), epochs=200, validation_data=(X_train_val, [Y_train_val,class_train_val]),callbacks=[tensorboard_callback])

"""View on tensorboard"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs

"""Save the model"""

newmod.save('/content/drive/My Drive/model_optV3') #the model_opt is better

modelviewer(history_tuned)

"""#First for the first model"""

import tensorflow as tf
model = make_model() 
model.summary()

logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)

model.compile(optimizer='adam', loss={'decoder_output':'binary_crossentropy','classification_output':'categorical_crossentropy'}, metrics={'decoder_output':'MAE','classification_output':'accuracy'})

epoch_number= 250
#batch_number= 32
#validation_number = 0.2

class_train_val.shape

history_1 = model.fit(mass_gen, steps_per_epoch=len(mass_gen), epochs=epoch_number, validation_data=(X_train_val, [Y_train_val,class_train_val]),callbacks=[tensorboard_callback])

"""View on tensorboard"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs

"""Save the model"""

model.save('/content/gdrive/My Drive/model_1')

"""We can optionally load the model"""

#from tensorflow import keras
#model = keras.models.load_model('/content/gdrive/My Drive/model_1')
#model.summary()

"""View the results"""

import matplotlib.pyplot as plt
def modelviewer(model):
  plt.figure(figsize=(8,8))
  plt.subplot(2,1,1)
  plt.title('autoencoder')
  plt.plot(model.history['decoder_output_loss'])
  plt.plot(model.history['val_decoder_output_loss'])
  plt.legend(['loss', 'val_loss'])
  plt.subplot(2,1,2)
  plt.title('classifier')
  plt.plot(model.history['classification_output_loss'])
  plt.plot(model.history['val_classification_output_loss'])
  plt.legend(['loss', 'val_loss'])
  return

modelviewer(history_1)

"""We visualize the output on images of the train set ..."""

idx=67
xtrain = X_train[idx][np.newaxis,...]
ytrain = Y_train[idx][np.newaxis,...]
xtrain.shape

print(np.argmax(model.predict(xtrain)[1]),class_train[idx])

plt.figure(figsize=(14,4))
plt.subplot(1,3,1)
plt.imshow(xtrain.squeeze())
plt.subplot(1,3,2)
plt.imshow(ytrain.squeeze())
plt.subplot(1,3,3)
plt.imshow(model.predict(xtrain)[0].squeeze()>0.2)

"""and on images of the test set (never seen by the CAE) """

idx=8
xtest = X_test[idx][np.newaxis,...]
ytest = Y_test[idx][np.newaxis,...]
xtest.shape

plt.figure(figsize=(14,4))
plt.subplot(1,3,1)
plt.imshow(xtest.squeeze())
plt.subplot(1,3,2)
plt.imshow(ytest.squeeze())
plt.subplot(1,3,3)
plt.imshow(model.predict(xtest)[0].squeeze()>0.2)

print(np.argmax(model.predict(xtest)[1]),class_test[idx])

"""Let's define the DICE index"""

def dice(pred, true, k = 1):
    intersection = np.sum(pred[true==k]) * 2.0
    dice = intersection / (np.sum(pred) + np.sum(true))
    return dice

"""We compute the Dice index for the train examples:"""

idx=13

xtrain = X_train[idx][np.newaxis,...]
ytrain = Y_train[idx][np.newaxis,...]
print(Y_train[idx].shape, ytrain.shape)

ypred = model.predict(xtrain)[0].squeeze()>0.2
ytrue = Y_train[idx].squeeze()
print(ypred.shape, ytrue.shape)

dice_value = dice(ypred, ytrue)
print(dice_value)

"""We want to compute the Dice index for all images in the np.arrays of the train and test sets"""

def dice_vectorized(pred, true, k = 1):
    intersection = 2.0 *np.sum(pred * (true==k), axis=(1,2,3))
    dice = intersection / (pred.sum(axis=(1,2,3)) + true.sum(axis=(1,2,3))) 
    return dice

dice_vectorized(ytrain,model.predict(xtrain)[0]>0.2)

"""The average Dice on the train set is:"""

dice_vectorized(Y_train,model.predict(X_train)[0]>0.2).mean()

dice_vectorized(Y_test,model.predict(X_test)[0]>0.2).mean()

import cv2
import matplotlib.image as mpimg
from keras import backend as K
import cv2
def blender(img1,img2,a,b):
  return  cv2.addWeighted(img1,a, img2, b,0)

import tensorflow as tf
from tensorflow.python.keras import backend as K
from tensorflow.keras import models
img_tensor =X_test[3][np.newaxis,...]
conv_layer = model_2.get_layer("last_conv")
heatmap_model = models.Model([model_2.inputs], [conv_layer.output, model_2.output])

# Get gradient of the winner class w.r.t. the output of the (last) conv. layer
with tf.GradientTape() as gtape:
    conv_output, predictions = heatmap_model(img_tensor)
    loss = predictions[1][:, np.argmax(predictions[1])]
    grads = gtape.gradient(loss, conv_output)
    pooled_grads = K.mean(grads, axis=(0, 1, 2))

heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)
heatmap = np.maximum(heatmap, 0)
max_heat = np.max(heatmap)
if max_heat == 0:
    max_heat = 1e-10
heatmap /= max_heat

print(heatmap.shape)

# Render heatmap via pyplot
plt.matshow(heatmap.squeeze())
plt.show()

model_2.get_layer("last_conv").output

import tensorflow as tf
from tensorflow.python.keras import backend as K
from tensorflow.keras import models

def heatmap(x,model):
  
  img_tensor =x[np.newaxis,...]
  preds = model.predict(img_tensor)[1]
  argmax = np.argmax(preds)
  conv_layer = model_2.get_layer("last_conv")
  heatmap_model = models.Model([model_2.inputs], [conv_layer.output, model_2.output])

  # Get gradient of the winner class w.r.t. the output of the (last) conv. layer
  with tf.GradientTape() as gtape:
      conv_output, predictions = heatmap_model(img_tensor)
      loss = predictions[1][:, np.argmax(predictions[1])]
      grads = gtape.gradient(loss, conv_output)
      pooled_grads = K.mean(grads, axis=(0, 1, 2))

  heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)
  heatmap = np.maximum(heatmap, 0)
  max_heat = np.max(heatmap)
  if max_heat == 0:
      max_heat = 1e-10
  heatmap /= max_heat

  #print(heatmap.shape)

  # Render heatmap via pyplot
  plt.matshow(heatmap.squeeze())
  plt.show()
    
  x = np.asarray(255*x, np.uint8)
  heatmap = np.asarray(255*heatmap.squeeze(), np.uint8)


  heatmap = cv2.resize(heatmap, (x.shape[1], x.shape[0]))

    
    #superimposed_img = heatmap * hif + x
  plt.imshow(blender(x,heatmap,1,1))
  plt.axis('off')
  if argmax==1:
    plt.title('the mass is malign')
  else:
    plt.title('the mass is benign')

heatmap(X_test[3],model_2)

"""Now the roc curve"""

from sklearn.metrics import roc_curve
y_pred = model.predict(X_test)[1]
fpr_keras, tpr_keras, thresholds_keras = roc_curve(class_test, [np.argmax(item) for _,item in enumerate(y_pred)])

from sklearn.metrics import auc
auc_keras = auc(fpr_keras, tpr_keras)

def plot_roc_curve(fper, tper):  
    plt.plot(fper, tper, color='orange', label='ROC')
    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend()
    plt.show()

plot_roc_curve(fpr_keras, tpr_keras)

"""#Now the second model"""

import tensorflow as tf
#tf.compat.v1.disable_eager_execution()


model_2 = make_modelREGULIZER() 
#model_2.summary()

logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)

epoch_number=250

model_2.compile(optimizer='adam', loss={'decoder_output':'binary_crossentropy','classification_output':'binary_crossentropy'}, metrics={'decoder_output':'MAE','classification_output':tf.keras.metrics.AUC()})

history_2 = model_2.fit(mass_gen, steps_per_epoch=len(mass_gen), epochs=epoch_number, validation_data=(X_train_val, [Y_train_val,class_train_val]),callbacks=[tensorboard_callback])

"""View on tensorboard"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs

"""Save the model"""

model_2.save('/content/drive/My Drive/model_2_sigmoid_200ep_binary')

"""We can optionally load the model"""

from tensorflow import keras
model_2 = keras.models.load_model('/content/drive/My Drive/model_2_sigmoid_200ep_binary')
model_2.summary()

"""View the results"""

modelviewer(history_2)

"""We visualize the output on images of the train set ..."""

idx=70
xtrain = X_train[idx][np.newaxis,...]
ytrain = Y_train[idx][np.newaxis,...]
xtrain.shape

plt.figure(figsize=(14,4))
plt.subplot(1,3,1)
plt.imshow(xtrain.squeeze())
plt.subplot(1,3,2)
plt.imshow(ytrain.squeeze())
plt.subplot(1,3,3)
plt.imshow(model_2.predict(xtrain)[0].squeeze()>0.2)

print(np.argmax(model_2.predict(xtrain)[1]),class_train[idx])

"""and on images of the test set (never seen by the CAE) """

idx=19
xtest = X_test[idx][np.newaxis,...]
ytest = Y_test[idx][np.newaxis,...]
xtest.shape

plt.figure(figsize=(14,4))
plt.subplot(1,3,1)
plt.imshow(xtest.squeeze())
plt.subplot(1,3,2)
plt.imshow(ytest.squeeze())
plt.subplot(1,3,3)
plt.imshow(model_2.predict(xtest)[0].squeeze()>0.2)

"""We compute the Dice index for the train examples:"""

idx=13

xtrain = X_train[idx][np.newaxis,...]
ytrain = Y_train[idx][np.newaxis,...]
print(Y_train[idx].shape, ytrain.shape)

ypred = model_2.predict(xtrain)[0].squeeze()>0.2
ytrue = Y_train[idx].squeeze()
print(ypred.shape, ytrue.shape)

dice_value_2 = dice(ypred, ytrue)
print(dice_value_2)

"""We want to compute the Dice index for all images in the np.arrays of the train and test sets"""

dice_vectorized(ytrain,model_2.predict(xtrain)[0]>0.2)

"""The average Dice on the train set is:"""

dice_vectorized(Y_train,model_2.predict(X_train)[0]>0.2).mean()

dice_vectorized(Y_test,model_2.predict(X_test)[0]>0.2).mean()

heatmap(X_test[19],model_2)

i=15
print(np.argmax(model_2.predict(X_test[i][np.newaxis,...])[1]),class_train[i])

"""Now the roc curve"""

from sklearn.metrics import roc_curve
y_pred = model_2.predict(X_test)[1]
fpr_keras, tpr_keras, thresholds_keras = roc_curve(class_test, [item[0] for _,item in enumerate(y_pred)],pos_label=0)

from sklearn.metrics import auc
auc_keras = auc(fpr_keras, tpr_keras)

def plot_roc_curve(fper, tper):  
    plt.plot(fper, tper, color='orange', label='ROC')
    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')
    
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve with AUC:%.2f'%auc_keras)
    plt.legend()
    plt.show()

plot_roc_curve(fpr_keras, tpr_keras)

"""#Now we try the third model"""

model_3 = make_modelDEEP() 
model_3.summary()

logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)

epoch_number=250

model_3.compile(optimizer='adam', loss={'decoder_output':'binary_crossentropy','classification_output':'binary_crossentropy'}, metrics={'decoder_output':'MAE','classification_output':tf.keras.metrics.AUC()})

history_3 = model_3.fit(mass_gen, steps_per_epoch=len(mass_gen), epochs=epoch_number, validation_data=(X_train_val, [Y_train_val,class_train_val]),callbacks=[tensorboard_callback])

"""View on tensorboard"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs

"""Save the model"""

model_3.save('/content/drive/My Drive/model_3')

"""We can optionally load the model"""

#from tensorflow import keras
#model_3 = keras.models.load_model('/content/drive/My Drive/model_3')
#model_3.summary()

"""View the results"""

modelviewer(history_3)

"""We visualize the output on images of the train set ..."""

idx=67
xtrain = X_train[idx][np.newaxis,...]
ytrain = Y_train[idx][np.newaxis,...]
xtrain.shape

plt.figure(figsize=(14,4))
plt.subplot(1,3,1)
plt.imshow(xtrain.squeeze())
plt.subplot(1,3,2)
plt.imshow(ytrain.squeeze())
plt.subplot(1,3,3)
plt.imshow(model_3.predict(xtrain)[0].squeeze()>0.2)

"""and on images of the test set (never seen by the CAE) """

idx=18
xtest = X_test[idx][np.newaxis,...]
ytest = Y_test[idx][np.newaxis,...]
xtest.shape

plt.figure(figsize=(14,4))
plt.subplot(1,3,1)
plt.imshow(xtest.squeeze())
plt.subplot(1,3,2)
plt.imshow(ytest.squeeze())
plt.subplot(1,3,3)
plt.imshow(model_3.predict(xtest)[0].squeeze()>0.2)
print(np.argmax(model_3.predict(xtest)[1]),class_test[idx])

"""We compute the Dice index for the train examples:"""

idx=13

xtrain = X_train[idx][np.newaxis,...]
ytrain = Y_train[idx][np.newaxis,...]
print(Y_train[idx].shape, ytrain.shape)

ypred = model_3.predict(xtrain)[0].squeeze()>0.2
ytrue = Y_train[idx].squeeze()
print(ypred.shape, ytrue.shape)

dice_value_3 = dice(ypred, ytrue)
print(dice_value_3)

"""We want to compute the Dice index for all images in the np.arrays of the train and test sets"""

dice_vectorized(ytrain,model_3.predict(xtrain)[0]>0.2)

"""The average Dice on the train set is:"""

dice_vectorized(Y_train,model_3.predict(X_train)[0]>0.2).mean()

dice_vectorized(Y_test,model_3.predict(X_test)[0]>0.2).mean()

heatmap(X_test[19],model_3)

i=15
print(np.argmax(model_3.predict(X_test[i][np.newaxis,...])[1]),class_train[i])

"""Now the roc curve"""

from sklearn.metrics import roc_curve
y_pred = model_3.predict(X_test)[1]
fpr_keras, tpr_keras, thresholds_keras = roc_curve(class_test, [item[0] for _,item in enumerate(y_pred)],pos_label=0)

from sklearn.metrics import auc
auc_keras = auc(fpr_keras, tpr_keras)

def plot_roc_curve(fper, tper):  
    plt.plot(fper, tper, color='orange', label='ROC')
    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')
    
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve with AUC:%.2f'%auc_keras)
    plt.legend()
    plt.show()

plot_roc_curve(fpr_keras, tpr_keras)

"""#Now the UNET model"""

model_4 = make_modelUNET() 
model_4.summary()

logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)

model_4.compile(optimizer='adam', loss={'decoder_output':'binary_crossentropy','classification_output':'binary_crossentropy'}, metrics={'decoder_output':'MAE','classification_output':tf.keras.metrics.AUC()})

history_4 = model_4.fit(mass_gen, steps_per_epoch=len(mass_gen), epochs=500, validation_data=(X_train_val, [Y_train_val,class_train_val]),callbacks=[tensorboard_callback])

"""View on tensorboard"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs

"""Save the model"""

#model_4.save('/content/drive/My Drive/model')

"""We can optionally load the model"""

from tensorflow import keras
model_4 = keras.models.load_model('/content/drive/My Drive/model_4_constraints_reg')
model_4.summary()

"""View the results"""

modelviewer(history_4)

"""We visualize the output on images of the train set ..."""

idx=67
xtrain = X_train[idx][np.newaxis,...]
ytrain = Y_train[idx][np.newaxis,...]
xtrain.shape

plt.figure(figsize=(14,4))
plt.subplot(1,3,1)
plt.imshow(xtrain.squeeze())
plt.subplot(1,3,2)
plt.imshow(ytrain.squeeze())
plt.subplot(1,3,3)
plt.imshow(model_4.predict(xtrain)[0].squeeze()>0.2)

"""and on images of the test set (never seen by the CAE) """

idx=16
xtest = X_test[idx][np.newaxis,...]
ytest = Y_test[idx][np.newaxis,...]
xtest.shape

plt.figure(figsize=(14,4))
plt.subplot(1,3,1)
plt.imshow(xtest.squeeze())
plt.subplot(1,3,2)
plt.imshow(ytest.squeeze())
plt.subplot(1,3,3)
plt.imshow(model_4.predict(xtest)[0].squeeze()>0.2)

"""We compute the Dice index for the train examples:"""

idx=13

xtrain = X_train[idx][np.newaxis,...]
ytrain = Y_train[idx][np.newaxis,...]
print(Y_train[idx].shape, ytrain.shape)

ypred = model_4.predict(xtrain)[0].squeeze()>0.2
ytrue = Y_train[idx].squeeze()
print(ypred.shape, ytrue.shape)

dice_value_4 = dice(ypred, ytrue)
print(dice_value_4)

"""We want to compute the Dice index for all images in the np.arrays of the train and test sets"""

dice_vectorized(ytrain,model_4.predict(xtrain)[0]>0.2)

"""The average Dice on the train set is:"""

dice_vectorized(Y_train,model_4.predict(X_train)[0]>0.2).mean()

dice_vectorized(Y_test,model_4.predict(X_test)[0]>0.2).mean()

heatmap(X_test[16],model_4)

i=16
print(np.argmax(model_4.predict(X_test[i][np.newaxis,...])[1]),class_train[i])

"""Now the roc curve"""

from sklearn.metrics import roc_curve
y_pred = model_4.predict(X_test)[1]
fpr_keras, tpr_keras, thresholds_keras = roc_curve(class_test, [item[0] for _,item in enumerate(y_pred)],pos_label=0)

from sklearn.metrics import auc
auc_keras = auc(fpr_keras, tpr_keras)

plot_roc_curve(fpr_keras, tpr_keras)

"""otsu's binarization"""

X_test[16].shape

segmented=otsu(model_4.predict(X_test[16][np.newaxis,...])[0].squeeze(),2)
plt.figure()
plt.imshow(segmented)

"""#Now let's analyze some of the results. What we want to do now is:
1) study how the binarization affects the dice index

2) see if the stability of the results depend on the seed of the set separation

3) study how a custom metric improves the result
"""

plt.figure('All models')

plt.plot(np.linspace(1,len(history_1.history['loss']),len(history_1.history['loss'])),history_1.history['loss'],label='train loss')
plt.plot(np.linspace(1,len(history_1.history['loss']),len(history_1.history['loss'])),history_1.history['val_loss'],label='val loss')
plt.plot(np.linspace(1,len(history_2.history['loss']),len(history_2.history['loss'])),history_2.history['loss'],label='train REG')
plt.plot(np.linspace(1,len(history_2.history['loss']),len(history_2.history['loss'])),history_2.history['val_loss'],label='val REG')
plt.plot(np.linspace(1,len(history_3.history['loss']),len(history_3.history['loss'])),history_3.history['loss'],label='train DEEP')
plt.plot(np.linspace(1,len(history_3.history['loss']),len(history_3.history['loss'])),history_3.history['val_loss'],label='val DEEP')
plt.plot(np.linspace(1,len(history_4.history['loss']),len(history_4.history['loss'])),history_4.history['loss'],label='train UNET')
plt.plot(np.linspace(1,len(history_4.history['loss']),len(history_4.history['loss'])),history_4.history['val_loss'],label='val UNET')
plt.ylabel('loss')
plt.xlabel('epochs')
#plt.ylim(0.035,0.05)
plt.title('loss models')
plt.grid()
plt.legend()
#plt.savefig('lossmodel_total.png')

"""1) Binarization and dice index"""

def ypredictor(models,alpha,xtrain):
  ypred=models.predict(xtrain)>alpha
  return ypred

maxdice_test=[]
maxdice_train=[]
alpha=np.round(np.linspace(0,1,10),1)
model_names=['base','Reg','Deep','Unet']
plt.figure(figsize=(12,12))
for i,mods in enumerate([model,model_2,model_3,model_4]):
  plt.subplot(2,2,i+1)
  plt.title('%s'%model_names[i])
  dices_test=[]
  dices_train=[]

  for _,alphas in enumerate(alpha):
    dices_test.append(dice_vectorized(Y_test,ypredictor(mods,alphas,X_test)).mean())
    dices_train.append(dice_vectorized(Y_train,ypredictor(mods,alphas,X_train)).mean())

  maxdice_test.append(alpha[np.where(dices_test==np.max(dices_test))])
  maxdice_train.append(alpha[np.where(dices_train==np.max(dices_train))])
  plt.plot(alpha,np.array(dices_test),marker='o',linestyle='dashed',label='Test')
  plt.plot(alpha,np.array(dices_train),marker='o',linestyle='dashed',label='Train')
  plt.xlabel('Binarize parameter')
  plt.ylabel('Average DICE index')
  plt.legend()
  plt.grid()

maxdice_test, maxdice_train,

"""here we define a simple segmentation function"""

from skimage.feature import canny
from scipy import ndimage as ndi
def filler(img,sigma):
  edges = canny(img,sigma)
  filled_mask = ndi.binary_fill_holes(edges)
  return filled_mask

def canny_dice(model,Y_test,X_test,sigma):
  dicess=[]
  filled_masks=[]
  for i in range(len(X_test[np.newaxis,...][0])): #make more efficient with np.map
    image=X_test[i][np.newaxis,...]
    real=Y_test[i][np.newaxis,...]
    filled_masks.append(filler(model.predict(image).squeeze(),sigma))
    dicess.append(dice(filler(model.predict(image).squeeze(),sigma),real.squeeze()))
  return np.array(dicess)

maxdicess_test=[]
maxdicess_train=[]
sigmas=np.round(np.linspace(0,5,10),1)
model_names=['base','Reg','Deep','Unet']
plt.figure(figsize=(12,12))
for i,mods in enumerate([model,model_2,model_3,model_4]):
  plt.subplot(2,2,i+1)
  plt.title('%s'%model_names[i])
  dicess_test=[]
  dicess_train=[]

  for _,alphas in enumerate(sigmas):
    dicess_test.append(canny_dice(mods,Y_test,X_test,alphas).mean())
    dicess_train.append(canny_dice(mods,Y_train,X_train,alphas).mean())

  maxdicess_test.append(sigmas[np.where(dicess_test==np.max(dicess_test))])
  maxdicess_train.append(sigmas[np.where(dicess_train==np.max(dicess_train))])
  plt.plot(sigmas,np.array(dicess_test),marker='o',linestyle='dashed',label='Test')
  plt.plot(sigmas,np.array(dicess_train),marker='o',linestyle='dashed',label='Train')
  plt.xlabel('sigma')
  plt.ylabel('Average DICE index')
  plt.legend()
  plt.grid()

"""As we can see the best results are from binarizing with the first method.

#Let's study the stability with varying test seed split (work on)
"""

# Commented out IPython magic to ensure Python compatibility.
def modeltrainerseeded(mod, seed):
  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=seed)
  X_train_tr, X_train_val, Y_train_tr, Y_train_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=24)
  mass_gen = MassesSequence(X_train_tr, Y_train_tr, train_datagen)
  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['MAPE'])   
  logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
  tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)
  history = model.fit(mass_gen, steps_per_epoch=len(mass_gen), epochs=250, validation_data=(X_train_val, Y_train_val), )
#   %tensorboard --logdir logs
  return history

seeds_used=np.random.randint(1,50,5)
max_mean_dice_test=[]
max_mean_dice_train=[]
for seeds in seeds_used:
  for i,mods in enumerate([model,model_2,model_3,model_4]):
  
    history_seed=modeltrainerseeded(mods, seeds)
    dices_test_new=[]
    dices_train_new=[]
    for _,alphas in enumerate(alpha):
      dices_test_new.append(dice_vectorized(Y_test,ypredictor(mods,alphas,X_test)).mean())
      dices_train_new.append(dice_vectorized(Y_train,ypredictor(mods,alphas,X_train)).mean())
    max_mean_dice_test.append(max(dices_test_new))
    max_mean_dice_train.append(max(dices_train_new))

max_mean_dice_test

max_mean_dice_test_np=np.array(max_mean_dice_test)
max_mean_dice_train_np=np.array(max_mean_dice_train)
np.savetxt('maxmeandicetest.txt',max_mean_dice_test_np)
np.savetxt('maxmeandicetrain.txt',max_mean_dice_train_np)

"""#Now we try to define the IOU metric (to work on)"""

# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow

def get_iou_vector(A, B):
    # Numpy version    
    batch_size = A.shape[0]
    metric = 0.0
    for batch in range(batch_size):
        t, p = A[batch], B[batch]
        true = np.sum(t)
        pred = np.sum(p)
        
        # deal with empty mask first
        if true == 0:
            metric += (pred == 0)
            continue
        
        # non empty mask case.  Union is never empty 
        # hence it is safe to divide by its number of pixels
        intersection = np.sum(t * p)
        union = true + pred - intersection
        iou = intersection / union
        
        # iou metrric is a stepwise approximation of the real iou over 0.5
        iou = np.floor(max(0, (iou - 0.45)*20)) / 10
        
        metric += iou
        
    # teake the average over all images in batch
    metric /= batch_size
    return metric

def iou_metric_batch2(y_trues_in, y_preds_in):
    y_trues_in=(y_trues_in>0)
    y_preds_in=(y_preds_in)
    unions = np.sum(y_preds_in|y_trues_in,(1,2))
    intersections=np.sum(y_preds_in*y_trues_in,(1,2))
    ious=np.maximum(0.0,np.ceil(20*intersections/np.where(unions==0.0,1,unions)-10)/10)
    return np.mean(np.where(unions==0,1,ious))

def my_iou_metric(label, pred):
    # Tensorflow version
    return tf.py_function(get_iou_vector, [label, pred > 0.5], tf.float32)

"""Define a learning rate scheduler"""

from keras.callbacks import Callback

class SnapshotCallbackBuilder:
    def __init__(self, nb_epochs, nb_snapshots, init_lr=0.1):
        self.T = nb_epochs
        self.M = nb_snapshots
        self.alpha_zero = init_lr

    def get_callbacks(self, model_prefix='Model'):

        callback_list = [
            Callbacks.ModelCheckpoint("./keras.model",monitor='val_loss', 
                                   mode = 'min', save_best_only=True, verbose=1),
            swa,
            Callbacks.LearningRateScheduler(schedule=self._cosine_anneal_schedule)
        ]

        return callback_list

    def _cosine_anneal_schedule(self, t):
        cos_inner = np.pi * (t % (self.T // self.M))  # t - 1 is used when t has 1-based indexing.
        cos_inner /= self.T // self.M
        cos_out = np.cos(cos_inner) + 1
        return float(self.alpha_zero / 2 * cos_out)

class SWA(keras.callbacks.Callback):
    
    def __init__(self, filepath, swa_epoch):
        super(SWA, self).__init__()
        self.filepath = filepath
        self.swa_epoch = swa_epoch 
    
    def on_train_begin(self, logs=None):
        self.nb_epoch = self.params['epochs']
        print('Stochastic weight averaging selected for last {} epochs.'
              .format(self.nb_epoch - self.swa_epoch))
        
    def on_epoch_end(self, epoch, logs=None):
        
        if epoch == self.swa_epoch:
            self.swa_weights = self.model.get_weights()
            
        elif epoch > self.swa_epoch:    
            for i in range(len(self.swa_weights)):
                self.swa_weights[i] = (self.swa_weights[i] * 
                    (epoch - self.swa_epoch) + self.model.get_weights()[i])/((epoch - self.swa_epoch)  + 1)  

        else:
            pass
        
    def on_train_end(self, logs=None):
        self.model.set_weights(self.swa_weights)
        print('Final model parameters set to stochastic weight average.')
        self.model.save_weights(self.filepath)
        print('Final stochastic averaged weights saved to file.')

def iou_metric_batch2(y_trues_in, y_preds_in):
    y_trues_in=(y_trues_in>0)
    y_preds_in=(y_preds_in)
    unions = np.sum(y_preds_in|y_trues_in,(1,2))
    intersections=np.sum(y_preds_in*y_trues_in,(1,2))
    ious=np.maximum(0.0,np.ceil(20*intersections/np.where(unions==0.0,1,unions)-10)/10)
    return np.mean(np.where(unions==0,1,ious))

"""Define a model trainer"""

# Commented out IPython magic to ensure Python compatibility.
def modelcompandtrain(model,metrics,epochs):
  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[metrics])   
  snapshot = SnapshotCallbackBuilder(nb_epochs=epochs,nb_snapshots=1,init_lr=1e-3)
  logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
  tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)
  history = model.fit(mass_gen, steps_per_epoch=len(mass_gen), epochs=epochs, validation_data=(X_train_val, Y_train_val), callbacks =snapshot.get_callbacks())
#   %tensorboard --logdir logs
  return history

def iou_metric(y_true_in, y_pred_in, print_table=False):
    labels = label(y_true_in > 0.5)
    y_pred = label(y_pred_in > 0.5)
    
    true_objects = len(np.unique(labels))
    pred_objects = len(np.unique(y_pred))

    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]

    # Compute areas (needed for finding the union between all objects)
    area_true = np.histogram(labels, bins = true_objects)[0]
    area_pred = np.histogram(y_pred, bins = pred_objects)[0]
    area_true = np.expand_dims(area_true, -1)
    area_pred = np.expand_dims(area_pred, 0)

    # Compute union
    union = area_true + area_pred - intersection

    # Exclude background from the analysis
    intersection = intersection[1:,1:]
    union = union[1:,1:]
    union[union == 0] = 1e-9

    # Compute the intersection over union
    iou = intersection / union

    # Precision helper function
    def precision_at(threshold, iou):
        matches = iou > threshold
        true_positives = np.sum(matches, axis=1) == 1   # Correct objects
        false_positives = np.sum(matches, axis=0) == 0  # Missed objects
        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects
        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)
        return tp, fp, fn

    # Loop over IoU thresholds
    prec = []
    if print_table:
        print("Thresh\tTP\tFP\tFN\tPrec.")
    for t in np.arange(0.5, 1.0, 0.05):
        tp, fp, fn = precision_at(t, iou)
        if (tp + fp + fn) > 0:
            p = tp / (tp + fp + fn)
        else:
            p = 0
        if print_table:
            print("{:1.3f}\t{}\t{}\t{}\t{:1.3f}".format(t, tp, fp, fn, p))
        prec.append(p)
    
    if print_table:
        print("AP\t-\t-\t-\t{:1.3f}".format(np.mean(prec)))
    return np.mean(prec)

def iou_metric_batch(y_true_in, y_pred_in):
    batch_size = y_true_in.shape[0]
    metric = []
    for batch in range(batch_size):
        value = iou_metric(y_true_in[batch], y_pred_in[batch])
        metric.append(value)
    return np.array(np.mean(metric), dtype=np.float32)

def my_iou_metric(label, pred):
    metric_value = tf.py_function(iou_metric_batch, [label, pred], tf.float32)
    return metric_value

def mean_iou(y_true, y_pred):
   return tf.metrics.mean_iou(y_true, y_pred, NUM_CLASSES)[1]

from keras import backend as K

K.get_session().run(tf.local_variables_initializer())

# Define IoU metric
def mean_iou2(y_true, y_pred):
    prec = []
    for t in np.arange(0.5, 1.0, 0.05):
        y_pred_ = tf.to_int32(y_pred > t)
        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2, y_true)
        K.get_session().run(tf.local_variables_initializer())
        with tf.control_dependencies([up_opt]):
            score = tf.identity(score)
        prec.append(score)
    return K.mean(K.stack(prec), axis=0)

def mean_iou(y_true, y_pred):
   score, up_opt = tf.metrics.mean_iou(y_true, y_pred, 2)
   K.get_session().run(tf.local_variables_initializer())
   with tf.control_dependencies([up_opt]):
       score = tf.identity(score)
   return score

logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))

tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)

epoch_number=250

model_2.compile(optimizer='adam', loss={'decoder_output':'binary_crossentropy','classification_output':'binary_crossentropy'}, metrics={'decoder_output':my_iou_metric,'classification_output':tf.keras.metrics.AUC()})

history_2 = model_2.fit(mass_gen, steps_per_epoch=len(mass_gen), epochs=epoch_number, validation_data=(X_train_val, [Y_train_val,class_train_val]),callbacks=[tensorboard_callback])



# Commented out IPython magic to ensure Python compatibility.
#   %tensorboard --logdir logs

"""#Now we try another approach to autoencoder + classification. We want to separate the autoencoder, train it, then use the pretrained encoder to train SEPARATELY the classifier. So we set the same seed in the transform generator, make a second mass_gen class to give a xtrain and a classification label and do that.

"""

